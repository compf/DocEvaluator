\newcommand{\checkpmd}{\textit{Checkstyle} und \textit{PMD} }
\newcommand{\doceval}{\textit{DocEvaluator} }
In diesem Kapitel soll das Programm evaluiert werden, um zu prüfen, ob das Programm (im Folgenden \textit{DocEvaluator}) den Anforderungen genügt.  Zunächst wird der \textit{DocEvaluator} mit \checkpmd{} verglichen, indem drei exemplarische Open-Source-Projekte mit allen drei Programmen analysiert werden und die Treffergenauigkeit und Geschwindigkeit der Programme verglichen werden. Außerdem wird  erläutert, welche Unit-Tests zur Verifikation des Programmverhaltens eingesetzt wurden.
\section{Vorgehensweise bei der Evaluation}
Zur Durchführung der Evaluation muss zunächst definiert werden, welche Funktionen der einzelnen Programme miteinander verglichen werden können, da die Programme unterschiedliche Aspekte der Dokumentation überprüfen und die Darstellung der Ergebnisse im Vergleich zum \textit{DocEvaluator} abweicht.

\checkpmd können als fehlersuchend bezeichnet werden. Sie prüfen die einzelnen Komponenten eines Programms und finden Abweichungen von vorher definierten Regeln. Eine solche Regel kann beispielsweise sein, dass jede öffentliche Methode dokumentiert sein muss, dass bestimmte Wörter nicht verwendet werden dürfen oder dass die Syntax der Dokumentation Fehler enthält. Damit sind sie vergleichbar mit den Metriken aus den Kapiteln \ref{chapter:metrics_coverage}  und \ref{chapter:metrics_errors}, welche ebenfalls bestimmte Fehler suchen und bei einem Verstoß gegen die Regeln eine Warnmeldung ausgeben. Allerdings berechnen\checkpmd keine Metriken, sondern finden nur die besagten Verstöße gegen die definierten Regeln. Somit kann ein Entwickler sehen, dasś ein Projekt beispielsweise 100 Verstöße gegen die Dokumentationsrichtlinien hat, erfährt aber nicht ob die Anzahl der Verstöße unter Berücksichtigung der Projektgröße schwerwiegend sind und erhält keine normierte Bewertung, die dem Entwickler bei der Beurteilung der Dokumentationsqualität hilft. 

Im Gegensatz dazu verwendet der \doceval Metriken , die stets einen Wert von 0 bis 100 zurückgeben, sodass ein Entwickler weiß, dass ein hoher Wert für eine hohe Qualität steht. Außerdem kann kann der \doceval auch die Semantik des Kommentars heuristisch prüfen, um zu erfahren, ob der Kommentar verständlich ist und nicht redundant ist (vgl. Kapitel \ref{chapter:metrics_semantic}). Nichtsdestotrotz gibt der \doceval auch Warnmeldungen aus, wenn er bestimmte Komponenten schlechter bewerten muss.

\section{Unit-Test}
Dir grundlegende Vorgehensweise zur Prüfung, ob ein Programm seinen Anforderung genügt, sind Unit-Tests. Bei Unit-Tests oder auch Modul- oder Komponententests wird eine genau abgegrenzte Komponente des Programms getestet. Dabei werden die Komponente zunächst in einem bestimmten Zustand gebracht, indem beispielsweise bestimmte Eingabeparameter vorgegeben werden. Anschließend werden bestimmte Operationen auf der Komponente angewendet. Am Schluss wird der Zustand der Komponente angefragt und geprüft, ob der Zustand der Komponente nach allen Operationen so ist, wie es gemäß den Anforderungen zu erwarten ist. Gibt es Abweichung beim Zustand, so wird der Entwickler sofort informiert. 

Im Kontext des Programmms wurden die drei Arbeitspakete Traversierung, Parsing und Bewertung durch Metriken getestet.
