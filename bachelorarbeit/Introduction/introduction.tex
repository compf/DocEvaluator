\label{sec:introduction}

Ein wichtiger Bestandteil der Softwareentwicklung von heute ist die Softwaredokumentation. Dies liegt unter anderem daran, dass die Größe von Softwareprojekten steigt, sodass kein Entwickler das gesamte Programm im Überblick hat und daher zusätzliche Informationen neben dem Code benötigt \cite[S. 1]{StaticAnalysis:AnIntroduction:TheFundamentalChallengeofSoftwareEngineeringisOneofComplexity.}. Nichtsdestotrotz wird die Softwaredokumentation von Entwicklern oft vernachlässigt \cite[S. 83]{Qualityanalysisofsourcecodecomments}.  Die Gründe für schlechte Dokumentation sind vielfältig. Das Schreiben der Dokumentation wird oft als mühevoll empfunden und erfordert Fähigkeiten, die ein Programmierer nichts zwangsläufig hat\cite[S. 70]{AutomaticQualityAssessmentofSourceCodeComments:TheJavadocMiner} \cite[S. 593]{Softwareengineeringandsoftwaredocumentation:aunifiedlongcourse}.  

Die mangelhafte Dokumentation führt dazu, dass nicht nur nachfolgende Entwickler Probleme mit dem Codeverständnis haben, sondern auch der Entwickler eines Moduls nach einer längeren Pause Zeit aufbringen muss, um den Code wieder zu verstehen. \cite[S. 511]{vestdam} Auch für Kunden/Auftraggeber ist eine gute Dokumentation wichtig, da gut dokumentierte Software tendenziell besser wartbar ist und somit mehr Nutzen bringt \cite[S. 83]{Qualityanalysisofsourcecodecomments}\cite[S. 1]{SoftwareDocumentationManagementIssuesandPractices:ASurvey}.


Dass in vielen Fällen die Softwaredokumentation vernachlässigt wird, ist durch viele Studien belegt. Eine Umfrage aus dem Jahr 2002 mit 48 Teilnehmern belegt beispielsweise, dass Anforderungs- oder Spezifikationsdokumente nur selten bei Änderungen am Quellcode angepasst werden. Außerdem finden 54\% der befragten Entwickler  Textverarbeitungsprogramme wie Word für hilfreich, die nicht für Dokumentationszwecke entwickelt wurden.Diese Programme sind leicht zu bedienen und sehr flexibel, aber nicht effizient  \cite[S. 28-29]{TheRelevanceofSoftwareDocumentationToolsandTechnologies:ASurvey}. 

Eine weitere Studie aus dem Jahr 2019 verdeutlicht viele Aspekte aus der vorgenannten Umfrage. Es wurden dabei Daten aus Stack Overflow, GitHub Issues und Pull Requests und Mailing-Listen automatisiert heruntergeladen und dann von den Autoren analysiert, ob und inwieweit mit mangelhafter Softwaredokumentation zu tun haben.  Die Studie liefert klare Indizien dafür, dass die Softwaredokumentation in vielen Fällen nicht komplett, nicht auf dem neuesten Stand oder sogar nicht korrekt ist. Des Weiteren ist die Softwaredokumentation nicht gut nutzbar oder schlecht lesbar, sodass der Vorteil verloren geht\cite[S.1201 -1204]{SoftwareDocumentationIssuesUnveiled}.







\section{Zielsetzung}
Aus diesen Gründen ist eine regelmäßige Rückmeldung über die Dokumentation von hoher Bedeutung. Eine Möglichkeit, dieses Feedback zu geben, sind spezielle Metriken, welche eine numerische Auskunft über die Qualität der Softwaredokumentation liefern. Diese Metriken liefern dem Programmierer eine gute Einschätzung, ob die Softwaredokumentation ausreichend ist oder eine Verbesserung sinnvoll wäre. Da es im Bereich der Softwaredokumentation, verschiedene Metriken gibt, ist es sinnvoll mehrere Metriken zu verwenden. Die Ergebnisse aller Metriken können dann kombiniert werden. Dabei ist es auch ratsam, die Metriken zu gewichten, weil nicht jede Metrik die gleiche Zuverlässigkeit und Relevanz besitzt.

Damit das Feedback über die Softwaredokumentation auch wahrgenommen wird, sollte die Qualität regelmäßig  überprüft werden. Dies kann automatisiert in \ac{CI/CD}-Prozess erfolgen, bei dem Software kontinuierlich getestet und für den Release (z.~dt. Veröffentlichung) vorbereitet werden kann. Durch CI/CD können Unternehmen effizienter und besser Software entwickeln. So konnte die ING NL die gelieferten Function-Points vervierfachen und die Kosten für einen Function-Point auf einen Drittel reduzieren \cite[S. 520]{Vassallo2016}.

Basierend auf diesen Überlegungen soll ein Tool(z.dt. Werkzeug) entwickelt werden. Dieses Tool soll ein gegebenes Software-Projekt analysieren und eine numerische Bewertung darüber abgeben, die eine heuristische Aussage über die Qualität der Softwaredokumentation trifft.  Dabei soll das Tool primär für Javadoc konzipiert werden, allerdings soll während der Entwicklung auch darauf geachtet werden, dass eine Portierung auf andere Programmiersprache möglichst einfach wird und die Bewertung der Dokumentation unabhängig von der Programmiersprache funktioniert. Ziel dabei soll es nicht sein, dass jede Komponente (wie z.~B. Methoden oder Klassen) dokumentiert sein muss, sondern dass die wichtigen Komponenten eine gute Dokumentationsqualität haben und somit die Wartung vereinfacht wird. 



\section{Gliederung}
Zur Umsetzung der Bachelorarbeit wird zunächst ein Einblick in das Thema Code-Smell (Kapitel \ref{chapter:code_smell}) gegeben, da schlechte Softwaredokumentation als Code-Smell angesehen werden kann. Anschließend muss der Begriff der Softwaredokumentation genauer definiert werden, da der Begriff so noch sehr unklar ist    (Kapitel \ref{chapter:documentation}). Zudem wird eine Einführung in Javadoc gegeben, da dieses Tool am Ende der Bachelorarbeit hauptsächlich Java und Javadoc verarbeiten soll (Kapitel \ref{chapter:javadoc}). 
Außerdem werden einige verwandte Programme vorgestellt, die ebenfalls die Qualität der Softwaredokumentation analysieren können. Des Weiteren werden einige wissenschaftliche Arbeiten zusammengefasst, die sich ebenfalls mit der Analyse von Softwaredokumentationen beschäftigen.

Um das Programm in dem \ac{CI/CD}-Prozess einzubinden, wird \enquote{GitHub Actions} verwendet. Dieser Service der Plattform GitHub \footnote{\href{https://github.com/}{Github Website (besucht am 07.01.2022)}} ermöglicht es, eigene Programme (oder Programme aus einer großen Auswahl von anderen Programmierern) auf den Quelltext auszuführen.  Diese Programme können dann Fehlermeldungen werfen, wenn es irgendwelche Probleme mit dem Quelltext gibt, sodass der Entwickler darauf aufmerksam wird und die Probleme lösen kann. Mit dieser Plattform ist damit möglich, die Qualität der Softwaredokumentation regelmäßig zu prüfen und bei einer deutlichen Unterschreitung den Entwickler durch Fehlermeldungen zu warnen.  Eine kurze Einführung in GitHub Actions erfolgt in Kapitel \ref{chapter:github_actions}

Danach wird erläutert, wie das Programm entwickelt wurde und welche Herausforderungen zu bewältigen waren. Zunächst muss das Tool die Dateien finden, die vermutlich Softwaredokumentation enthalten und als relevant angesehen werden. Jede dieser Datei muss dann in einzelne Komponenten zerlegt werden, wobei jede Komponente einen Verweis auf ihre Dokumentation (z~B. Javadoc) enthält. Als Komponente im Sinne dieser Bachelorarbeit werden dabei Klassen, Schnittstellen, Methoden und Felder verstanden.

Als nächstes wird beschrieben, wie das Tool zu einer numerischen Bewertung der Qualität der Softwaredokumentation gelangt. Dazu werden verschiedene Metriken angewendet, die in Kapitel \ref{chapter:metrics} erläutert werden. Das Ergebnis jeder Metrik wird dann geeignet aggregiert, damit der Benutzer des Tools eine grobe Einschätzung der Qualität der Dokumentation hat. Beispielsweise kann ein arithmetischer Mittelwert oder ein gewichteter Mittelwert gebildet werden. 

In Anschluss wird in Kapitel \ref{chapter:github_actions_impl}  wird die Einbindung des Tools in GitHub Actions erläutert. Dazu muss das Programm in ein kompakteres Format gebracht werden und in einer separaten Branch in GitHub hochgeladen werden. 

Anschließend soll das Tool mit anderen Tools, die ebenfalls die Dokumentationsqualität bewerten können, verglichen werden. Dazu werden ausgewählte Java-Projekte aus GitHub mit allen Tools analysiert und die Ergebnisse der Tools verglichen. 
\section{Verwandte Werkzeuge}
Um die Qualität der Softwaredokumentation in Javadoc zu bewerten, gibt es bereits einige Programme. In vielen Fällen handelt es sich dabei um Programme, die nicht auf die Bewertung der Softwaredokumentation beschränkt sind, sondern auch andere Fälle von unsauberem Code erkennen können. Da die Bewertung der Dokumentation nicht der primäre Zweck der Programme ist, sind die verwendeten Metriken recht allgemein und erkennen viele Problemfälle nicht. Nichtsdestotrotz sind diese Programme, dadurch dass sie viele \enquote{Code-Smells} erkennen, sehr gut geeignet, um sich ein gutes Bild über die Qualität des Quellcodes zu verschaffen und den Entwickler zu Clean-Code zu motivieren. 
\subsubsection{Checkstyle}
Eines der bekanntesten Programme ist Checkstyle \footnote{\href{https://checkstyle.sourceforge.io/}{Checkstyle Website (besucht 07.01.2022)}}. Mit Checkstyle lässt sich beispielsweise prüfen, ob alle Methoden überhaupt ein Javadoc-Block besitzen, der Javadoc-Block korrekt platziert wurde oder ein Javadoc-Tag wie zum Beispiel \enquote{@deprecated} auch mit einer zusätzlichen Begründung versehen wurde. 
\subsubsection{PMD}
Des Weiteren gibt es das Programm PMD\footnote{\href{https://pmd.github.io/}{PMD Website (besucht 07.01.2022)}}, das ebenfalls einige Metriken für Javadoc mitliefert. Dazu gehört, ob jede öffentliche Methode dokumentiert wurde oder die Kommentare generell zu lang sind. Interessanterweise gibt es auch die Möglichkeit, bestimmte Wörter, die als anstößig empfunden werden, aus Kommentaren und Dokumentationen auszuschließen, damit Kommentare neutral bleiben. 
\subsubsection{Javadoc}
Das oben erwähnte Javadoc-Tool bietet ebenfalls die Möglichkeit, beim Generieren der HTML-Datei die Qualität des Javadocs zu prüfen. Dabei werden vor allem fehlende Tags für Parameter etc. bemängelt. Zudem erkennt Javadoc auch Tabellen mit fehlender Überschrift und andere Designmängel, die in der HTML-Seite später auffallen. Auch fehlerhaftes HTML kann erkannt werden.

\section{Verwandte Arbeiten}

Neben den praktischen Tools, die den Softwareentwickler bei der Bewertung der Softwaredokumentation unterstützen, wurden auch einige wissenschaftliche Arbeiten veröffentlicht, die sich mit Metriken über Softwaredokumentation auseinandersetzen. 


\subsubsection{Quasoledo}\label{chapter:Quasoledo}
In \cite[S. 4-10]{HowDocumentationEvolvesoverTime} geben die Autoren einige Metriken an, die sie für die Bewertung der Softwaredokumentation als nützlich erachten, und stellen ein Programm namens \textit{Quasoledo} vor, dass mittels dieser Metriken Softwaredokumentationen analysieren kann . Zu den Metriken gehören z.~B.  \textit{ANYJ},  welches den Anteil der dokumentierten Deklarationen an allen Deklarationen beschreibt und in Kapitel \ref{chapter:metrics_simple_comment} genauer erläutert wird, und \textit{KINCAID}, welches die Lesbarkeit von Texten beschreibt und in einer abgewandelten Form von  \ref{chapter:metrics_flesh} genauer beschrieben wird. 

Die Arbeit wertet anschließend die Javadoc-Dokumentation von Eclipse aus und findet heraus, dass öffentliche Methoden häufiger dokumentiert sind und ihre Dokumentation oft lesbarer ist. Außerdem wenden die Autoren das Tool auf die gesamte Versionshistorie von Eclipse bis zum 8. April 2006 an und plotten den Verlauf der Dokumentationsqualität über diesem Zeitraum. Dabei wird sichtbar, dass die Qualität am Anfang des Projektes noch sehr stark schwankt, aber nach einiger Zeit recht konstant bleibt. 
\subsubsection{JavaDocMiner}
Eine weitere Arbeit, die eine der Grundlagen dieser Bachelorarbeit ist, ist der \enquote{JavaDocMiner} \cite[S. 68-79]{AutomaticQualityAssessmentofSourceCodeComments:TheJavadocMiner}. In diesem Konferenzpapier wird ein Programm beschrieben, welches mittels einfachen Heuristiken eine Einschätzung der Softwaredokumentation beschrieben. Das Tool extrahiert aus XML-Dateien, die mittels eines selbst geschriebene Doclet aus Javadoc erstellt wurden, die notwendigen Informationen und wendet dann auf diese XML-Struktur die Metriken an. 

Insgesamt verwendeten die Autoren viele Metriken aus Kapitel \hyperref[chapter:Quasoledo]{Quasoledo}, führen aber auch Metriken ein, die Anzahl der Abkürzungen zählen, da diese laut der Arbeit vermieden werden sollten. Auch die durchschnittliche Anzahl an Wörtern pro Javadoc-Kommentar wird als Metrik verwendet. 

Anschließend wendeten die Autoren das Tool auf den Quellcode an und prüften, ob es eine Korrelation zwischen der Anzahl an Bugs und der Qualität der Dokumentation nach den benannten Metriken und fanden dabei heraus, dass die Kincaid-Metrik nur wenig mit der Anzahl der Bugs korreliert, während andere Metriken wie z. B. \textit{ANYJ} eine starke negative Korrelation gab. 

\subsubsection{Doc2Spec}
Die Autoren in \cite[S. 307ff.]{InferringResourceSpecificationsfromNaturalLanguageAPIDocumentation} erläutern ein Verfahren, um herauszufinden, ob eine API korrekt verwendet wurde. Dabei werden die Javadoc-Kommentare einer API analysiert und dann mit der Verwendung der API verglichen, um Fehler bei der Handhabung der API zu finden. 

Für jede dokumentierte Methode der API wird ein Aktion-Ressource-Paar erstellt. Diese beschreibt welche Aktion auf welche Ressource ausgeführt. Bei einer Methode namens \textit{close}, die mit dem englischen Text \enquote{Initiates close of the connection handle at the
application level} dokumentiert wird, lässt sich beispielsweise schlussfolgern, dass das Aktion-Ressource-Paar \textit{(close,connection)} sein kann; denn die Aktion \textit{close} bezieht sich auf die Ressource \textit{connection}. Dabei sind aber manchmal mehrere Aktion-Ressource-Paare möglich\cite[S. 308]{InferringResourceSpecificationsfromNaturalLanguageAPIDocumentation}.

Anschließend werden die gefundenen Ressourcen anhand der Klassenhierarchie passend gruppiert. Außerdem werden die Aktionen in fünf Kategorien eingeordnet,in der die meisten Java-Methoden passen. Die Kategorien sind Methoden, die eine Ressource oder Objekt erstellen, eine Ressource sperren, auf eine Ressource zugreifen, eine gesperrte Ressource wieder freigeben und Ressourcen schließen. 

Mit diesen generierten Informationen kann dann bei Quelltext, welches diese API verwendet, geprüft werden, ob die Methoden dieser Ressource in der richtigen Reihenfolge aufgerufen werden. Beispielsweise muss eine Ressource zuerst erzeugt und gesperrt werden, bevor irgendwelche Manipulationen angewendet werden. Außerdem kann geprüft werden, ob eine Ressource auch wieder freigegeben und geschlossen wird, sodass Speicherlecks verhindert werden. Dabei werden alle möglichen Ausführungspfade einer Methode geprüft, da ein fehlendes Freigeben von Ressourcen z.~B. im Ausnahmefall ein häufiger Fehler sein kann. 

\subsubsection{iComment}
Das Programm\textit{}{\/\*iComment}  wurde hauptsächlich für C-Programme entwickelt, um Probleme zwischen der Dokumentation und dem Quellcode zu finden. Dabei konzentriert sich das Programm auf das Finden von Synchronisationsproblemen, die bei Programmen mit mehreren Threads auftauchen können.  Bei einem exklusiven Ausschluss besitzt eine Methode einen sogenannten Lock auf ein Objekt und nur diese Methode darf mit dem Objekt arbeiten.

Setzt nun die Dokumentation einen Lock voraus, aber der Programmierer hat keinen Lock angefordert, können sehr schnelle und subtile Bugs entstehen, die nur schwer findbar sind. \cite[S. 145ff.]{icomment}

Das Programm wurde auf dem Quellcode des Linux-Kernels und Mozilla angewandt und dabei mögliche Bugs gefunden, die später auch von den Entwicklern bestätigt wurden\cite[S. 146.]{icomment}.
\subsubsection{@tComment}
Ein anderer Ansatz, der ebenfalls mit Javadoc arbeitet, heißt \enquote{@tComment}\cite[S. 1ff.]{@tComment:TestingJavadocCommentstoDetectComment-CodeInconsistencies}. Dabei wurden die Konsistenz der Javadoc-Dokumentation mit dem tatsächlichen Programmcode verglichen. Anders als die vorherigen Ansätze, wird hier das Programm dynamisch ausgeführt. Dabei werden die verschiedenen Methoden und ihr dazugehörige Javadoc-Dokumentation analysiert und daraus mittels einfacher Heuristiken ermittelt, ob ein  Nullwert für einen Parameter eine Inkonsistenz zwischen Dokumentation und Quellcode offenbart.

Beispielsweise kann die Dokumentation einer Java-Methode beschreiben, dass ein Parameter nicht null sein darf. Daraus kann gefolgert werden, dass ein Nullwert für diesen Parameter zu einer Ausnahme führt. Wenn diese Ausnahme dann auch genauer in der Dokumentation genauer spezifiziert ist, sollte genau diese Ausnahme bei einem Nullwert geworfen werden. 

Falls Nullwerte explizit erlaubt sind, sollte die Methode sich dann stets korrekt verhalten und keine Ausnahmen werfen. 

\enquote{@tComment} kann mit diesen einfachen Regeln jede Methode ausführen und prüfen, ob sich die Methode tatsächlich verhält, wie die Dokumentation es beschreibt. Dabei verwendet das Programm einfache \ac{NLP}-Heuristiken in der englischen Sprache; zum Beispiel prüft das Programm, ob die kurz vor dem Wort \enquote{null} ein negierendes Wort wie \enquote{not} oder \enquote{never} auftaucht und klassifiziert dann den dazugehörigen Parameter als Parameter, der nie null sein darf. 







