\section{Implementierte Metriken}\label{chapter:metrics}
Im Folgenden werden die Metriken präsentiert, die in der finalen Version des \textit{JavadocEvaluator} implementiert worden sind. Dabei werden pro Metrik einige Vor- und Nachteile genannt, um den zukünftigen Anwender eine Entscheidungshilfe zu bieten. 
\subsection{Metrik: Anteil dokumentierter Komponenten an allen Komponenten}\label{chapter:metrics_simple_comment}
Bei dieser Metrik werden dokumentierte Komponenten mit hundert Punkten bewertet, während undokumentierte Komponenten null Punkte erhalten. Dabei ist es irrelevant, wie gut die Dokumentation ist. Selbst die leere Dokumentation \textbf{/***/} würde ein Rating von 100 erhalten, da hier eine weitergehende Differenzierung zwar umsetzbar ist, aber dafür eine davon abgeleitete Metrik besser geeignet wäre. Vorteilhaft an dieser Metrik ist die Einfachheit der Implementierung. Außerdem ist sie als grober Indikator gut geeignet, die Qualität der Dokumentation abzuschätzen. Ein Nachteil an dieser Metrik ist, dass sie auch sinnlose Kommentare, die leer oder nichts mit der dokumentierten Komponente zu tun haben, mit der vollen Punktzahl bewertet werden. Außerdem bestehen moderne Softwareprojekte aus vielen verschiedenen Komponenten, wobei einige Komponenten nur an einigen wenigen Stellen verwendet werden und daher nur selten dokumentiert wurden. Aus diesen Grund würde diese Metrik die \enquote{wahre} Dokumentationsqualität unterschätzen. 
Diese Metrik wurde unter anderem in \cite[S. 5]{HowDocumentationEvolvesoverTime} erläutert und dort als \enquote{ANYJ} bezeichnet. Da dies einfache Metrik ist und für eine grobe Einschätzung der Qualität der Dokumentation geeignet ist, wurde diese Metrik im Tool implementiert.

\subsection{Metrik: Anteil dokumentierter öffentlicher Komponenten an allen öffentlichen Komponenten }\label{chapter:public_members}
Diese Metrik basiert auf der vorherigen Metrik und verwendet sie sogar intern. Im Unterschied zu dieser werden hier nur öffentliche Komponenten betrachtet. Dies bedeutet, dass alle nicht öffentlichen Komponenten so betrachtet werden, als wären sie nicht existent. Die öffentlichen Komponenten dagegen werden wie oben mit hundert bzw. null Punkten bewertet. Dies hat den Vorteil, dass nur die Komponenten, die wahrscheinlich von anderen Komponenten verwendet werden müssen und daher auch gut verstanden werden müssen, bei der Bewertung der Qualität der Dokumentation berücksichtigt werden. So hat der Entwickler einen guten Überblick über die Stellen, die nach gängiger Erfahrung unbedingt besser dokumentiert werden müssen. Auf der anderen Seite werden sinnlose Kommentare weiterhin akzeptiert und nicht öffentliche Komponenten werden ohne Berücksichtigung ihrer Wichtigkeit ignoriert, obwohl auch hier eine gute Dokumentation Fehler vermeiden kann und zu einer besseren Softwarequalität führen kann. 

Diese Metrik wurde unter anderem von \cite{Doautomaticrefactoringsimprovemaintainability?Anindustrialcasestudy} verwendet, um die Wirkung von Refactorings zu analysieren, Auch PMD und Checkstyle besitzen Optionen, um nur öffentliche Komponenten zu analysieren, sodass diese Metrik durchaus Relevanz hat und daher implementiert wurde.

 
 \subsection{Metrik: Vollständigkeit der Dokumentation von  Methoden}\label{chapter:method_doc}
 
Viele Methoden in objektorientierten Programmiersprachen besitzen Parameter und haben einen Rückgabewert. Diese stellen die Eingabe und Ausgabe der Methode dar und müssen genau verstanden werden, um sie korrekt anzuwenden. Dazu ist eine gute Dokumentation sinnvoll. In Javadoc und vielen anderen Dokumentationssystemen können einzelne Parameter dokumentiert werden. Zur Bewertung der Dokumentation kann geprüft werden, wie viele Parameter der Methode dokumentiert sind. Demgegenüber können auch Parameter dokumentiert werden, die gar nicht mehr existieren. Dies kann beispielsweise das Resultat von einem Refactoring sein. Diese \enquote{Phantomparameter} können verwirren und zu Problemen führen, sodass es auch hier sinnvoll ist, die fehlerhaft dokumentierten Parameter gezählt werden können. In dieser Metrik jeweils der Anteil der falsch dokumentierten Parameter (seien sie existent aber nicht dokumentiert oder dokumentiert aber nicht existent) berechnet und so eine Bewertung ermittelt.
 
 Dazu sollte auch der Rückgabewert überprüft werden. Eine Methode ohne Dokumentation des Rückgabewertes wird mit null Punkten bewertet, während eine Methode mit dokumentierten Rückgabewert mit hundert Punkten bewertet wird. Natürlich werden dabei Methoden, die \enquote{void} zurückgeben oder Konstruktoren auch mit hundert Punkten bewertet, da diese keinen dokumentierbaren Rückgabewert besitzen. 
 
 Diese Metrik wird auch in Checkstyle implementiert, das auf nicht dokumentierte Parameter hinweist. In der wissenschaftlichen Literatur wird diese Metrik unter anderem in \cite[S. 5]{HowDocumentationEvolvesoverTime} genannt und dort als \enquote{DIR} bezeichnet. Da eine vollständig dokumentierte Methode zu einer guten Dokumentationsqualität beiträgt, wurde auch diese Metrik aufgenommen.

\subsection{Ignorieren von Getter und Setter }
Getter und Setter sind typische Konstrukte in objektorientierten Programmiersprachen, die es ermöglichen, auf ein gekapseltes Feld zu lesen oder es zu verändern. Dadurch ermöglichen sie einen kontrollierten Zugriff auf die Felder und können so Fehler vermeiden \cite[S. 235]{OntheUseofPropertiesinJavaApplications}. Viele dieser Getter- und Setter-Methoden werden oft nicht dokumentiert, da sie nur triviale Codezeilen enthalten und sehr kurz sind, sodass eine Dokumentierung den Code aufbläht und keine Vorteile bietet. \cite[S. 254]{JavadocViolationsandTheirEvolutioninOpen-SourceSoftware}. Auch Checkstyle bietet die Option an, diese trivialen Methoden bei der Analyse der Softwaredokumentation auszuschließen. Daher gibt es für die Metriken in Kapitel \ref{chapter:metrics_simple_comment} und \ref{chapter:public_members} die Option, Getter und Setter auszuschließen.

Nicht trivial ist dagegen die Implementierung einer Metrik, die Getter- und Setter-Methoden ausschließt. Laut der JavaBeans-Spezifikation \cite[S. 55]{javabeans} sollen diese Zugriffsmethoden mit dem Präfix \enquote{get} bzw. \enquote{set} beginnen. Außerdem besitzt ein Getter keine Parameter und besitzt einen Rückgabetyp. Ein Setter sollte den Rückgabetyp \enquote{void} haben und exakt ein Parameter übergeben bekommen. Abweichend davon können Getter, die einen Boolean zurückgeben, mit dem Präfix \enquote{is} beginnen. Die Namenskonvention ist allerdings sprachspezifisch und noch kein eindeutiges Indiz für einen Getter bzw. Setter. Nichtsdestotrotz wurde entschieden die Filterung nach den JavaBeans-Kriterien durchzuführen und dafür eine Möglichkeit anzubieten, die Namenskonvention nach eigenen Wünschen zu konfigurieren. 

Der Vorteil des Ausschließens von Getter und Setter wurde bereits genannt. Die Kommentare von diesen Zugriffsmethoden sind oft repetitiv und enthalten keinen Mehrwert, sodass sie überlesen werden und der größere Code sogar unübersichtlicher wird. Allerdings sollte die dazugehörigen Felder trotzdem dokumentiert werden, um ihren Sinn und Zweck zu begründen. Dies wird hier nicht durchgesetzt, sodass es dazu kommen kann, dass Felder nicht dokumentiert sind und auch die dazugehörigen Zugriffsmethoden keine Hilfe bieten. Dies führt vermutlich zu einer schlechteren Lesbarkeit, da jedes Feld eine Bedeutung hat, die nicht immer offensichtlich ist.
\subsection{Flesch-Reading Ease Score}\label{chapter:metrics_flesh}
Der Flesch-Reading-Ease-Score\cite[S. 21]{ThePrinciplesofReadability} ist eine einfache Formel zur heuristischen Ermittlung der Lesbarkeit eines englischsprachigen Textes. Dabei werden die Anzahl der Sätze, die Anzahl der Wörter und die Anzahl der Silben im Text als Eingabeparameter. Die Formel lautet:
\begin{equation}
   206.835-1.015*\frac{W}{S}-84.6*\frac{H}{W}
\end{equation}. Dabei ist $S$ die Anzahl der Sätze, $W$ die Anzahl der Wörter und $H$ die Anzahl der Silben. 

Die Formel liefert normalerweise einen Wert von 0 bis 100 zurück. Dabei bedeutet der Wert 0, dass der Text sehr kompliziert geschrieben ist und nur von Personen mit akademischer Bildung gut verstanden werden kann. Ein Wert von 100 bedeutet dagegen, dass der Text sehr einfach aufgebaut ist und daher schon von einem Fünftklässler verstanden werden kann. Diese Formel und verwandte Formeln werden auch von verschiedenen US-Behörden verwendet, um die Lesbarkeit ihrer Dokumente zu verbessern\cite[S. 72]{AutomaticQualityAssessmentofSourceCodeComments:TheJavadocMiner}

Die Flesch-Metrik nutzt diese Formeln, um eine Bewertung der Softwaredokumentation zu erhalten. Dabei wird angenommen, dass ein Flesch-Score von ca. 70 optimal ist. Dokumente mit einer Bewertung von 60 - 70 werden von etwas mehr als 80 Prozent der erwachsenen US-Bevölkerung verstanden, sodass diese Texte lesbar genug sein sollten.

Aus diesen Grund wurde eine mathematische Funktion ermittelt, die für einen Flesch-Score von 70 eine Bewertung von 100 zurückgibt. Für einen größeren Flesch-Score wird eine lineare Funktion verwendet, die für einen sehr leichten Text (Flesh-Score 100 oder darüber) eine Bewertung von 85 zurückgibt. Damit sollen Programmierer für sehr leichte Texte nicht stark bestraft, aber trotzdem ermuntert werden einen für technische Dokumentationen angemessenen Text zu schreiben.

Für einen Flesch-Score unter 70 wird eine quadratische Funktion verwendet, die einen Flesch-Score von 60 noch sehr fair behandelt, aber kleinere Flesch-Scores, die auf einen komplizierten Text hindeuten, deutlich schlechter bewertet werden. Damit sollen Entwickler dazu ermuntert werden, ihre Texte nicht allzu kompliziert zu gestalten. Dies hilft nachfolgenden Entwicklern, aber auch dem Erzeuger der Dokumentation, beim Verständnis des Quellcodes und verhindert so potenzielle Bugs.

Bei der Verwendung des Flesch-Scores sollte beachtet werden, dass die Bewertung von Flesch bei kurzen Texten, zum Beispiel aus nur einem Satz, stark fluktuiert. Außerdem ist die Bestimmung der Silbenzahl eines Wortes nicht immer trivial; bei der Entwicklung des Tools musste bei einem Austausch einer Bibliothekt die Testmethode angepasst werden, da das Wort \enquote{themselves} plötzlich drei statt zwei Silben hatte. Dies hängt natürlich auch von der Aussprache und somit von kulturellen Gegebenheiten ab. Dies gilt natürlich auch für Wörter und Sätze. 
\subsubsection{Parameter}
\begin{itemize}
    \item \textit{consider\_tags} Wenn true, berechne den Mittelwert aus allen Flesch-Score der einzelnen Tags und der allgemeinen Beschreibung des Javadocs, standardmäßig false
\end{itemize}
\subsection{Metrik:Kohärenz zwischen Kommentar und Komponentenname}\label{chapter:metrics_coherence}
Die Dokumentation einer Komponente sollte einen Mehrwert bieten und nicht nur den Namen der Komponente wiederholen  Gleichzeitig sollte es einen Zusammenhang zwischen den Namen einer Komponente und dessen Dokumentation geben, da ansonsten keine gute Beziehung hergestellt werden kann\cite[S. 86-87]{Qualityanalysisofsourcecodecomments}. Um diese Beziehung mittels einer Metrik bewerten zu können, kann die Anzahl der Wörter bestimmt werden, die sowohl im Komponentennamen als auch in der Dokumentation auftauchen. Durch Division dieser Anzahl durch die Gesamtzahl der Wörter wird der \textbf{Koheränzkoeffizient} berechnet. Die Autoren in \cite[S. 86-87]{Qualityanalysisofsourcecodecomments} wenden diesen Koeffizienten nur auf Methodennamen an und vertreten die Auffassung, dass ein Koheränzkoeffizient von 0 bzw. über 0.5 auf eine schlechte Dokumentierung hindeuten, da im ersten Fall es keine Verbindung zwischen den Kommentar und der Komponente gibt und im zweiten Fall zu viele Gemeinsamkeiten existieren. Diese Metrik nutzt die ermittelten Ober- und Untergrenze des Koheränzkoeffizienten für alle Komponenten, da die Beschränkung auf Methoden nicht sinnvoll ist und auch andere Komponenten einen nicht repetitiven Kommentar haben sollten. Außerdem sind die Grenzen hier parametrisierbar, um die Handhabung der Metrik auf unterschiedliche Situationen zu erleichtern. Komponenten ohne Dokumentation werden hier vollstädnig ignoriert. 

Um die Zahl der  gemeinsamen Wörter zwischen Komponentenname und Dokumentation zu ermitteln, wird der Name der Komponente nach den zwei üblichen Namenskonventionen zerlegt( Trennung bei Unterstrich und beim Aufeinanderfolgen von Klein- und Großbuchstaben (Pascal-Case)). Eine Komponente \textit{getText} würde in die Wörter \textit{get} und \textit{Text} aufgespalten werden. Ebenso würde der Name \textit{get\_text} in  \textit{get} und \textit{text} zerlegt werden. Zur Vereinfachung werden alle Wörter in Kleinbuchstaben konvertiert. 

Die Anzahl der gemeinsamen Wörter wird bestimmt, indem jedes Wort aus der allgemeinen Beschreibung mit jedem Wort aus dem Komponentennamen verglichen wird. Für jedes Wörterpaar wird die Levenshtein-Distanz berechnet, welche die minimale Anzahl an Operationen beschreibt, um aus einem Wort ein anderes zu bilden \cite[S. 1091]{ANormalizedLevenshteinDistanceMetric} Ist  die Levenshtein-Distanz kleiner oder gleich Eins, so werden die Wörter als gemeinsam betrachtet. Dieser Grenzwert kann allerdings auch parametrisiert werden. Durch die Verwendung der Levenshtein-Distanz können leichte Schreibfehler ignoriert werden. 

Der Koheränzkoeffizient muss anschließend in den notwendigen Wertebereich von 0 bis 100 gebracht werden. Eine direkte Verwendung durch Multiplikation mit 100 wäre widersinnig, da dann ein hoher Koheränzkoeffizient , durch welchen der Komponenentenname und Kommentar (nahezu) übereinstimmen, positiv bewertet wird. Daher werden Koeffizienten kleiner oder gleich der Untergrenze und auch Koeffizenten größer der Obergrenze mit null Punkten bewertet. Alle anderen Komponenten mit einen Koheränzkoeffizient zwischen diesen Werten werden mit 100 Punkten bewertet. Eine andere Möglichkeit wäre es, die Bewertung mittels einer stetigen mathematischen Funktion von dem Koheränzkoeffizienten abhängig zu machen, sodass ein Koeffizient zwischen der Unter- und Obergrenze nicht konstant mit 100 Punkten bewertet wird. Allerdings muss dazu ein Koeffizient gefunden werden, der mit 100 Punkten bewertet werden soll; hierzu fehlt es an wissenschaftlichen Studien, die einen solchen Wert bestimmen, sodass hier darauf verzichtet wird. 

Mit dieser Metrik können Entwickler dazu angeregt werden, informative Kommentare zu schreiben, die nicht nur eine Wiederholung des Komponentennamens sind. Dadurch bietet die Dokumentation einen größeren Mehrwert und kann beispielsweise Informationen über den Zweck einer Komponente oder mögliche Fehlerquellen bei der Benutzung hinweisen. Auf der anderen Seite ist es nicht trivial, gemeinsame Wörter zu finden, da Synonyme oder Wörter mit vielen Rechtschreibfehler nicht als gemeinsames Paar erkannt werden. Zudem  kann durch die Verwendung von Füllwörtern (wie z.~B. \textit{the}, \textit{of} etc.) die Bewertung unterschätzt werden, da diese aktuell im Nenner des Koheränzkoeffizienten auftauchen. Eine Filterung wäre möglich, würde jedoch nie abschließend sein und könnte zu Problemen führen, wenn solche Füllwörter auch im Komponentennamen verwendet werden. Zuletzt sind Kommentare bei kurzen Methoden (wie z.~B. Getter oder Setter) oft trivial und können in einigen Fällen keine nennenswerten Informationen enthalten, sodass diese Metrik aufgrund der Ähnlichkeit von Komponentennamens mit dem Kommentar eine Bewertung von null Punkten zurückgibt. 

  \subsubsection{Parameter}
  \begin{itemize}
     \item \textit{lower\_threshold} maximaler Wert für den  Koheränzkoeffizienten, bei dem ein geringer Zusammenhang vermutet wird und daher mit null Punkten bewertet wird
    \item \textit{upper\_threshold} minimaler Wert für den  Koheränzkoeffizienten, bei dem ein zu großer Zusammenhang vermutet wird und daher mit null Punkten bewertet wird
\item \textit{levenshtein\_distance} maximale Levenshtein-Distanz, bei denen zwei Wörter als ähnlich angesehen werden. 
 \end{itemize}
\subsection{Metrik: Verwendung bestimmter Wörter bestrafen}\label{chapter:metric_certain_words}
Nach \cite{HowtoWriteDocCommentsfortheJavadocTool} sollte ein Kommentar keine lateinischen Ausdrücke verwendet werden. So sollten beispielsweise die folgenden Ausdrücke geändert werden
\begin{itemize}
    \item {e.g.} durch \enquote{for example}
    \item \enquote{aka} durch \enquote{also known as}
    \item \enquote{i.e.} durch \enquote{that is} 
    
\end{itemize}
Diese Metrik greift die Empfehlung auf und ermöglicht es zusätzlich, eigene Wörter als unzulässig zu definieren. So können obszöne Begriffe oder bestimmte Abkürzungen bestraft werden. Jedes Vorkommen eines unzulässigen Begriffes wird gezählt. Um eventuelle kleinere Rechtschreibfehler zu ignorieren wird auch hier mittels einer maximalen Levenshtein-Distanz nach unzulässigen Wörtern gefiltert.

Anschließend wird diese Anzahl der Funktion
\begin{equation}
     B(l))S-(S-B_0)*e^(-k*l)
 \end{equation} übergeben, die eine beschränkt wachsende Exponentialfunktion ist. Dabei ist $S$ die untere Schranke für die Bewertung, $B_0$ die beste Bewertung,  $k$ eine Konstante für die Wachstumsrate und $l$ die Zahl der unzulässigen Wörter. 
  Die Konstante $k$ kann vom Benutzer der Metrik frei ermittelt werden; ein Wert von $k=0.1$ scheint jedoch passend zu sein, da so das Auftauchen eines Begriffes noch nicht allzu hart bestraft wird, bei mehreren unzulässigen Begriffen allerdings schon.
  
  Durch diese Metrik kann ein Style-Guide eines Unternehmens, der von der Verwendung bestimmter Begriffe in Javadoc abrät, besser durchgesetzt werden. So lassen sich Begriffe, die unklar sind oder nicht geläufig sind vermeiden, sodass die Verständlichkeit der Dokumentation erhöht wird. Andererseits ist die Wahl dieser Begriffe nicht trivial und aufgrund der Verwendung der Levenshtein-Distanz können falsch-positive Treffer zu einer Verzerrung des Ergebnisses führen
  \subsubsection{Parameter}
\begin{itemize}
    \item \textit{consider\_tags} Wenn true, zähle die Treffer auch in den einzelnen Tags standardmäßig false
    \item \textit{k} Der Wachstumsfaktor für das beschränkte Wachstum
    \item \textit{levenshtein\_distance} Die maximale Levenshtein-Distance, damit zwei Wörter als ähnlich gelten
    \item \textit{terms} alle unzulässigen Wörter
    \item \textit{use\_default\_terms\_too} Wenn true, nutze auch die in \cite{HowtoWriteDocCommentsfortheJavadocTool} beschriebenen Begriffe auch wenn durch Verwendung eigener Begriffe diese überschrieben wurden
\end{itemize}

 \section{Eigene Metriken}
 Im Folgenden werden Metriken aufgegriffen, die kaum in der wissenschaftlichen Literatur erwähnt werden, aber durchaus eine Betrachtung wert sind. Auch hier werden einige Vor- und Nachteile der jeweiligen Metrik genannt.
 \subsection{Metrik: Bestrafung von undokumentierten langen Methoden}\label{chapter:method_long}
Es wird grundsätzlich empfohlen, möglichst kurze Methoden zu schreiben und längere Methoden in mehrere kleinere Methoden aufzuspalten. Jede Methode sollte dabei nicht mehr als vier Codezeilen lang sein \cite[S. 34]{martin2009clean}.
 
 Dennoch wird diese Empfehlung nicht immer befolgt. Im Kontext der Softwaredokumentation sollten diese größeren Methoden allerdings umso eher dokumentiert werden, da es ansonsten schwieriger ist, die Bedeutung der verschiedenen Parameter, des Rückgabewertes und allgemeinen Rolle der Funktion zu erfassen. Daher macht es Sinn undokumentierte Methoden mit vielen Codezeilen schlechter zu bewerten.
 
 Genau dafür wurde diese Metrik entwickelt. Jede Methode enthält unstrukturiert alle Befehle, Verzweigungen etc. Durch Splitten am Zeilenende lässt sich eine grobe Schätzung für die Anzahl der Codezeilen finden. Anschließend wird diese Information an eine beschränkt wachsende Funktion (siehe Kapitel \ref{chapter:metric_certain_words}) übergeben, um so einen Wert zwischen 0 bis 100 zu ermitteln. 
  Um lange undokumentierte Methoden besser bestrafen zu können, wird eine Fallunterscheidung vorgenommen.
 
 Bei kurzen Methoden unter zehn Zeilen beträgt die untere Schranke der Funktion 90, da kurze Methoden nicht allzu schlecht bewertet werden sollen. Für Methoden mit mindestens zehn Zeilen sollte eine strengere Bewertung existieren, da diese wahrscheinlich unübersichtlicher sind. Aus diesem Grund werden längere Methoden mit nicht mehr als 90 Punkten und minimal null Punkten bewertet, sodass die Spannweite größer ist und die Bewertung schneller gegen null tendiert.
 
 Die Konstante $k$ ist hier standardmäßig  0.2, da Methoden mit bis zu zehn Zeilen noch relativ gut bewertet werden und längere Methoden gut bestraft werden. Er kann jedoch angepasst werden-
 
 Diese Metrik wird allerdings nur auf undokumentierte Methoden angewendet, sodass dokumentierte Methoden wie bei der Metrik \textit{SimpleCommentPresentMetric} mit 100 Punkten bewertet werden. Andere Komponenten wie zum Beispiel Klassen werden hier vollständig ignoriert, sodass sie keinen Einfluss auf das Gesamtergebnis haben.
 \subsubsection{Parameter}
 \begin{itemize}
     \item \textit{k} Die Wachstumsrate des beschränktes Wachstum
     \item \textit{ignore\_lines} Zeilen, die bei der Berechnung der \ac{LOC} ignoriert werden sollen
 \end{itemize}
     

 \subsection{Anteil dokumentierter Methoden an allen Methoden unter Berücksichtigung der LOC}\label{chapter:metrics_loc_ratio}
Diese Metrik ist relativ ähnlich zu der vorherigen Metrik. Allerdings arbeitet diese Metrik auf dem Level von hierarchischen Komponenten (z. B. Klassen) und summiert die \ac{LOC} der dokumentierten und undokumentierten Methoden und ermittelt daraus den Anteil der dokumentierten \ac{LOC} an allen \ac{LOC}. Dadurch werden längere Methoden wichtiger als kürzere, wodurch undokumentierter Getter- oder Setter-Methoden nicht so negativ bewertet werden. In Unterschied zu der vorherigen Metrik werden auch kommentierte Methoden nach ihrer Länge bewertet, anstatt wie bei der vorherigen Metrik stets mit 100 Prozent. Dies hat den Vorteil, dass jede dokumentierte Methode anhand ihres Gewichts in puncto \ac{LOC} gewichtet wird und der Entwickler für viele dokumentierte Methoden, die in vielen Fällen mehrere Codezeilen lang sind, eher belohnt wird als bei der vorherigen Metrik. Allerdings sollte auch erwähnt werden, dass hierdurch lange Methoden, auch wenn diese kommentiert sind, positiv bewertet werden, was eindeutig gegen die Grundsätze aus \cite[S. 34]{martin2009clean} verstößt. Zudem sollte es klar sein, dass eine undokumentierte lange Methode wahrscheinlich unverständlicher ist als eine gleich lange dokumentierte Methode. Da diese beiden Methoden sich dann bei dieser Metrik ausgleichen, würde die Qualität der Softwaredokumentation nur unzureichend widergespiegelt werden.
  \subsubsection{Parameter}
  \begin{itemize}
     \item \textit{ignore\_lines} Zeilen, die bei der Berechnung der \ac{LOC} ignoriert werden sollen
 \end{itemize}
 