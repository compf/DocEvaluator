\chapter{Konzeption}
Im Folgenden wird ein Konzept für die Implementierung des Tools vorgestellt, das  die Ziele der Bachelorarbeit erfüllen soll.
\section{Traversierung aller relevanten Dateien}\label{chapter:traversing}
Softwareprojekte bestehen aus Hunderten von Dateien, die nicht alle Quellcode enthalten. Beispielsweise gehören Konfigurationsdateien, Ressourcedateien wie Bilder oder binäre Dateien zu den Dateien, bei denen eine Analyse der Softwaredokumentation im Hinblick auf die begrenzte Zeit für die Bachelorarbeit nicht implementierbar ist. Daher ist es sinnvoll, bestimmte Dateien bei der Analyse auszuschließen beziehungsweise nur bestimmte Dateien zu betrachten. Bei einer Weiterentwicklung des Tools nach Abschluss der Bachelorarbeit kann das Tool auf andere Dateitypen ausgeweitet werden, um so ein besseres Gesamtbild über die Softwaredokumentation zu erhalten.

Um die relevanten Dateien zu finden, wird zunächst ein übergeordnetes Verzeichnis benötigt, was bei Softwareprojekten aber der Standard sein sollte. Dieses Verzeichnis kann dann rekursiv durchlaufen werden und somit die Liste aller darin gespeicherten Dateien abgerufen werden. Die relevanten Dateien können dann durch Überprüfung ihres Dateinamens mittels bestimmter Regeln ermittelt werden, die der Benutzer des Tools festlegen kann.

Beim JavadocEvaluator wird hierzu die NPM-Bibliothek Minimatch \footnote{\href{https://github.com/isaacs/minimatch}{Minimatch GitHub-Repository (besucht am 07.01.2022)}} verwendet, die es ermöglicht, Dateinamen mit Wildcard-Patterns zu vergleichen. Zum Beispiel könnte der Dateiname \enquote{test.txt} mit der Wildcard \enquote{test.*} verglichen werden und die Bibliothek würde eine Übereinstimmung melden.

\section{Parsing der Java-Dateien} 
Jede Datei, die relevant sein soll, muss anschließend weiterverarbeitet werden. Für die Bewertung der Dokumentation sind nur wenige Bestandteile relevant. Beispielsweise sind alle For-Schleifen, If-Verzweigungen und viele andere Komponenten in Methodenrümpfen nicht relevant, da diese nur mit normalen Kommentaren und nicht mit Javadoc kommentiert werden; (sie werden dennoch unstrukturiert als Zeichenkette gespeichert, damit Metriken diese Information eventuell nutzen können). Aus diesem Grund müssen die notwendigen Informationen extrahiert werden. Zudem ist es ein Ziel der Arbeit , eine Erweiterbarkeit auf andere objektorientierte Programmiersprachen zu ermöglichen. Daher müssen die Informationen in ein abstraktes Format gebracht werden, welches eine gute Annäherung für die meisten objektorientierten Programmiersprachen ist. Beispielsweise unterscheiden sich die Zugriffsmodifizierer vieler Programmiersprache, sodass eine einheitliche Schnittstelle schwer umsetzbar ist. Daher enthält die abstrakte Repräsentation nur Informationen, ob eine Komponente als öffentlich markiert ist. Dies ist sinnvoll, da öffentliche Komponenten als Teil der öffentlichen Schnittstelle eher dokumentiert werden sollten als nicht öffentliche und eine weitergehende Differenzierung kaum Vorteile bietet. In einigen Programmiersprachen wie z. B. Python gibt es keine expliziten öffentliche Komponenten, jedoch existieren de facto Standards für Bezeichner, sodass beispielsweise private Komponenten zwei Unterstriche als Präfix haben.

Außerdem werden in der abstrakten Repräsentation die Vererbung etwas vereinfacht dargestellt, indem nicht zwischen Basisklassen und Schnittstellen unterschieden wird, da es auch hier Unterschiede zwischen Programmiersprachen gibt, und die Informationen über die Vererbung, falls sie überhaupt von einer Metrik verwendet wird, vermutlich nicht so detailreich sein müsste. Zudem werden Konstruktoren als Methoden mit den Namen \enquote{constructor} und Schnittstellen als Klassen repräsentiert, da auch hier eine zu feine Spezifikation nicht notwendig sein wird.  

  

In anderen Fällen gibt es jedoch viele Gemeinsamkeiten zwischen objektorientierten Programmiersprachen; so gibt es in  allen relevanten Sprachen Klassen, Methoden und Felder, die alle einen Namen haben. Des Weiteren haben Methoden und Felder einen (Rückgabe-)Type und Methoden besitzen Parameter, die ihrerseits durch einen Namen und einen Typen definiert sind. Einige Sprachen sind zwar nicht stark typisiert, jedoch kann für nicht bekannte Datentypen ein Alias wie \enquote{Any} oder  \enquote{Object} verwendet werden.  Zudem sind viele Komponenten hierarchisch; in den meisten Sprachen können beispielsweise Klassen andere Klassen enthalten, sodass diese abstrakte Struktur diese Tatsache berücksichtigen müsste. 

Um dennoch sprachspezifische Funktionen anbieten zu können, besitzt jede Komponente ein Feld mit dem Typen \textit{ComponentMetaInformation}, das wie oben erwähnt die Information enthält, ob eine Komponente als öffentlich angesehen werden soll. Dieser Typ, welches eine Schnittstelle ist, kann von einer Klasse implementiert werden, um Parser für andere Programmiersprachen die Möglichkeit zu geben, zusätzliche sprachspezifische Informationen zu speichern. Beim Java-Parser wird diese Funktion beispielsweise genutzt, um zu speichern welche \enquote{checked} Ausnahmen eine Methode werfen kann, sodass später ein Vergleich mit der Javadoc möglich ist. Die Schnittstelle enthält nur die Anforderung, eine \textit{isPublic}-Methode anzubieten und kann daher für viele andere objektorientierte Programmiersprache Informationen speichern, die für einige Metriken eventuell nützlich sind. 
 \clearpage
 \begin{figure}[ht!]
 \begin{tikzpicture}
 \pgfmathsetlengthmacro\breite{6cm}
\pgfmathsetlengthmacro\hoehe{2.567cm}
\pgfmathsetlengthmacro\InnerSep{0.4cm}
\node[draw,
anchor=center, 
inner sep=0pt, 
minimum width=5cm, text width=6cm-\InnerSep,
align=justify,
minimum height=\hoehe
] (java) {
  \hspace*{0.1cm}\textbf{public} \textbf{class} Main\{.\newline 
     \hspace*{0.5cm}\textbf{private} \textbf{int} test(\textbf{int} a)\{\newline
    \hspace*{0.5cm}\}\newline
\hspace*{0.1cm}\}

};
\node[draw,text width=5.5cm, left = of java](python){
\textbf{class} Main:\newline
     \hspace*{0.5cm}\textbf{def} \_\_test(a:\textbf{int}): -> \textbf{int}\newline
         \hspace*{1cm}pass

};
\draw[line width=0.05cm] (python) -- (-4,-2.5) ;
\draw [line width=0.05cm](java) -- (-4,-2.5);
\draw[->,thick,line width=0.05cm] (-4,-2.5) -- (-4,-3.5);
\draw [] (-9,-3.5) rectangle(4,-16);
\begin{scope} {0,-10}
       \begin{object}[text width=8cm]{fileObj}{-4,-4}
        \instanceOf{FileComponent}
        \attribute{name = "filepath"}
        \attribute{parent = null}
        \attribute{children={[}classObj{]}}
      \end{object}
      \begin{object}[text width=8cm]{classObj}{-4,-8 }
        \instanceOf{ClassComponent}
        \attribute{name="Main"}
        \attribute{parent=fileObj}
        \attribute{children={[}methodObj{]}}
          \attribute{metaInformation=meta}
      \end{object}
    \begin{object}[text width=8cm]{methodObj}{-4,-12}
        \instanceOf{MethodComponent}
        \attribute{name="test"}
        \attribute{parent=classObj}
        \attribute{params={[}paramsObj{]}}
        \attribute{metaInformation=meta2}
        \attribute{returnType=int}
      \end{object}
      \begin{object}[text width=2.5cm]{paramObj}{2,-10}
        \attribute{name=a}
        \attribute{type=int}
      \end{object}
    \begin{object}[text width=2.5cm]{meta}{2,-6}
        \attribute{isPublic=true}
      \end{object}
    \begin{object}[text width=2.5cm]{meta2}{2.5,-14.5}
        \attribute{isPublic=false}
      \end{object}
\end{scope}
\begin{scope}[line width=0.05cm]
    \aggregation{fileObj}{}{}{classObj}{}{}
     \aggregation {classObj}{}{}{methodObj}{}{}
      \aggregation {methodObj}{}{}{paramObj}{}{}
    \aggregation {classObj}{}{}{meta}{}{}
        \aggregation {methodObj}{}{}{meta2}{}{}
\end{scope}

    
\end{tikzpicture}
     
     \caption{Objektdiagramm aus Java- und Python-Code}
     \label{fig:python_java_comp}
 \end{figure}


Abbildung \ref{fig:python_java_comp} veranschaulicht wie eine einfache Datei in die Objektstruktur umgewandelt werden kann. Dabei wird ein einfache Java-Klasse und eine semantisch äquivalente Python-Datei als Beispiel verwendet, um zu zeigen, dass aus beiden Sprachen eine gleiche Objektstruktur erzeugt werden kann. Dabei wurden zur Übersichtlichkeit einige nicht relevanten Attribute entfernt.

Das Programm in beiden Sprachen besteht aus einer öffentlichen Klasse \textit{Main} und einer privaten Methode \textit{test}, die einen Parameter \textit{a} als Ganzzahl erhält und eine Ganzzahl zurückgibt. Die höchste Hierarchieebene ist immer ein \textit{FileComponent}. Diese Datei enthält hier genau ein Kind namens \textit{classObj}, könnte aber in anderen Fällen auch mehrere Kinder (wie z.~B. Klassen enthalten). Die Klasse besitzt zudem einen Verweis auf ihren Elternteil. Außerdem enthält das \textit{classObj} eine Referenz auf MetaInformationen, die hier nur angeben, dass die Klasse öffentlich ist. In diesen MetaInformationen könnte auch die Basisklasse und andere relativ sprachspezifische Informationen enthalten. Die Klasse enthält wiederum genau die Methode als einziges Kind. Die Methode hat ebenfalls einen Verweis auf Metainformation, welche die Methode als privat markieren. Außerdem hat die Methode einen \textit{returnType} und einen Verweis auf die Liste der Parameter, die wiederum aus einen Namen und einen Datentyp bestehen.

\section{ANTLR4}
Um die Java-Dateien zu parsen, wird die Bibliothek ANTLR4\footnote{\href{https://www.antlr.org/}{ANTLR Website (besucht 07.01.2022)}} verwendet, die kostenlos verfügbar ist. Diese Bibliothek kann nicht nur viele Programmiersprachen, sondern auch selbst geschriebene Sprachen parsen, sofern eine passende Grammatik verfügbar ist. Daneben gibt es noch Bibliotheken wie Bison, PEG.JS, die ebenfalls eine ähnliche Aufgabe erfüllen können. Allerdings gibt es bereits vordefinierte Grammatiken für ANTLR4, sodass ein erheblicher Aufwand gespart werden konnte.  

Eine andere Möglichkeit zum Parsen der Java-Dateien ist die NPM-Bibliothek \enquote{java-parser} \footnote{\href{https://www.npmjs.com/package/java-parser}{Java-Parser (besucht 07.01.2022)}}. Dies hätte den Vorteil, dass das Parsen, welches nicht der Hauptfokus dieser Bachelorarbeit ist, ausgelagert wird und so Fehler vermieden werden. Allerdings kann diese Bibliothek nicht die Verbindung zwischen einer Komponente und der dazugehörigen Javadoc herstellen, sodass eine Benutzung dieser Bibliothek die Arbeit deutlich erschwert hätte. Daher fiel die Wahl auf \textit{ANTLR4}. Außerdem besteht die Möglichkeit, eine eigene Grammatik für Java zu schreiben, da die originale Grammatik für Java sämtliche Kommentare ignoriert. Da dies jedoch deutlich komplizierter war als erwartet, wurde dennoch entschieden, die von vielen Entwicklern geschriebene Grammatik zu verwenden (siehe Kapitel \ref{chapter:antlr4_impl}).

\section{Lexer und Parser}
Eine Grammatik für Programmiersprachen besteht immer aus einer Lexer-Grammatik und eine Parser-Grammatik, die jeweils vom Lexer bzw. Parser in dieser Reihenfolge verarbeitet werden, um so eine Baumstruktur einer Quellcodedatei zu erhalten. Der Lexer erstellt aus einer Quellcodedatei eine Liste von Tokens. Dabei ist ein Token eine Gruppierung von einem oder mehreren Zeichen, die eine weitergehende Bedeutung haben. Beispielsweise können Schlüsselwörter einer Programmiersprache oder Operatoren als Token klassifiziert werden. Diese Tokens sind grundsätzlich kontextunabhängig, das heißt für die gleiche Zeichenkette wird das gleiche Token verwendet. Jeder Token wird durch seine Zeichenkette und den Tokentyp klassifiziert

Listing \ref{lst:lexer_example} zeigt zur Verdeutlichung der Syntax eine Zeile aus der Lexer-Grammatik. 
		\begin{figure} [htbp]
			\lstinputlisting
			[caption={Beispielhafte Syntax vom Lexer},
			label={lst:lexer_example},
			captionpos=b, basicstyle=\footnotesize, tabsize=2, showstringspaces=false,  numbers=left]
			{figures/lexer_example.g4}
		\end{figure}

Eine Zeile in der Lexer-Grammatik beginnt mit den Namen eines Tokens, gefolgt von einem Doppelpunkt und dann einem regulären Ausdruck, der dieses Token beschreibt. In der beispielhaften Lexer-Grammatik wird ein Javadoc-Kommentar definiert, das mit \enquote{/**} beginnt, dann folgen beliebige Zeichen und endet mit \enquote{*/}. Per Konvention haben die Bezeichner der Tokens nur Großbuchstaben, sie müssen auf jeden Fall mit einem Großbuchstaben beginnen \cite[S. 3]{ANTLR:APredicated-<i>LLk</i>ParserGenerator}. 

Der nächste Schritt ist das  Parsen. Dabei werden die im vorherigen Schritt generierten Tokens, die als Liste vorliegen, genommen und in eine hierarchische Baumstruktur umgewandelt, wobei hier der Kontext die entscheidende Rolle spielt. ANTLR4 lädt ein Token nach dem anderen und prüft ob es, basierend auf der aktuellen Position in der Baumstruktur, eine Regel gibt, die durch diesen Token erfüllt wird. Wenn es mehrere mögliche Pfade gibt, lädt ANTLR4 so viele Tokens bis die nächste Regel eindeutig feststeht. Gibt es dennoch Uneindeutigkeiten, so wird die Regel genommen, die als erstes in der Parser-Datei geschrieben wurde.\cite[S. 10ff.]{TheDefinitiveANTLR4Reference}

So kann eine vereinfachte Parser-Grammatik für Java einen Baumknoten definieren, der eine generelle Methode beschreibt. Eine Methode besteht aus Rückgabetyp, Bezeichner und Parameterliste. Die Parameterliste kann dann als eine Liste von Datentyp-Bezeichner-Paare aufgelöst werden. Der Rückgabetyp einer Methode ist allerdings anders zu verstehen als der Datentyp eines Parameters, da jeder Datentyp eines Parameters auch ein gültiger Rückgabetyp ist, was jedoch nicht umgekehrt der Fall ist; so ist \textit{}{void} ein gültiger Rückgabetyp, aber kein Datentyp. Listing \ref{lst:parser_example} zeigt einen typischen Ausschnitt aus einer Parser-Grammatik, wobei zur Übersichtlichkeit nicht alle Regeln und Tokens aufgelistet sind:
		\begin{figure} [htbp]
			\lstinputlisting
			[caption={Beispielhafte Syntax vom Parser},
			label={lst:parser_example},
			captionpos=b, basicstyle=\footnotesize, tabsize=2, showstringspaces=false,  numbers=left]
			{figures/parser_example.g4}
		\end{figure}
		
Listing \ref{lst:parser_example} beschreibt die notwendigen Regeln, um Methodenparameter zu parsen. Ein Methodenparameter (Z. 1) kann keinen, einen oder mehrere  Modifizierer (Z. 2) enthalten, die ihrerseits eine Java-Annotation oder das Schlüsselwort\textit{final}  sein können (Z. 6-7). Anschließend (Zeile 3) muss ein Datentyp (Z. 9) erfolgen, der wiederum aus einer Annotation bestehen kann (Z. 10), gefolgt von entweder einem primitiven Datentyp oder einem Klassen bzw. Schnittstellentyp (Z.11). Auch die üblichen eckigen Klammern für Arrays in Java können nach diesem Datentyp folgen (Z. 12). Die letzte Voraussetzung für einen gültigen Methodenparameter ist ein valider Bezeichner (Z. 4), der in Zeile 14-16 genauer definiert wird. 

Die Parser-Grammatik ist ähnlich wie die der Lexer-Grammatik aufgebaut. Auch hier wird eine Variante der regulären Ausdrücken verwendet, wobei hier die reguläre Grammatik auf die Tokens angewendet wird. Anstelle des Namens des Tokens kann alternativ auch die Zeichenkette des Tokens verwendet werden (bspw. \enquote{+} statt \enquote{ADD}). Im Gegensatz zum Lexer muss der Bezeichner einer Parser-Regel mit einem Kleinbuchstaben beginnen\cite[S. 3]{ANTLR:APredicated-<i>LLk</i>ParserGenerator}. So ist eine Unterscheidung zwischen Tokens und den Parserregeln stets möglich. 


Basierend auf dieser Baumstruktur des Parsers kann eine Quellcodedatei analysiert werden und so alle relevanten Informationen gesammelt werden. 
Dies ist relativ leicht mit dem Visitor-Pattern möglich, da so nur die relevanten  Komponenten genauer betrachtet werden müssen und alle uninteressanten Komponenten automatisiert durchlaufen werden, bis eine relevante Komponente gefunden wird.

		\begin{figure} [htbp]
			\lstinputlisting
			[caption={Codeauschnitt aus  Methoden-Visitor},
			label={lst:visit_method_example},
			captionpos=b,language=java, basicstyle=\footnotesize, tabsize=2, showstringspaces=false,  numbers=left]
			{figures/visit_method_example.java}
		\end{figure}
Das Listing \ref{lst:visit_method_example} zeigt einen Ausschnitt vom Visitor für Methodendeklarationen. Hier ist die Baumstruktur leicht sichtbar. Alle Einzelbestandteile einer Methode wie z. B. Bezeichner, Rückgabetyp etc. sind Kindknoten des \textit{RuleContext} und können über die Methode \textit{getChild} abgerufen werden. So werden sowohl der Bezeichner als auch der Rückgabetyp direkt als Text abgerufen. Diese  beiden Bestandteile bestehen wiederum auch aus weiteren Kindknoten, doch eine weitergehende Betrachtung ist nicht nötig, da nur die Bezeichnung als Zeichenkette benötigt wird. Andere Bestandteile wie die Methodenparameter sind jedoch komplexer, aus diesem Grund werden sie von separaten Visitors betrachtet.

\section{Konzeption der Metriken}
Nachdem eine Datei in ihre einzelnen Komponenten zerlegt wurde, kann die Qualität der Softwaredokumentation überprüft werden. Jede gefundene Komponente besitzt einen Verweis auf die dazugehörige Dokumentation, die bei Nichtvorhandensein auch null sein kann. Anhand dieser Referenz kann geprüft werden, ob die Softwaredokumentation der Komponente ausreichend ist. Zur Bewertung der Dokumentation gibt es verschiedene  Möglichkeiten. Beispielsweise könnte überprüft werden, ob eine Komponente dokumentiert oder undokumentiert ist. Eine weitere Möglichkeit wäre es die Verständlichkeit der Dokumentation zu prüfen. Jedes dieser Vorgehen basiert auf eine Metrik, die auf wissenschaftliche Studien beruht oder zumindest plausibel ist. In diesem Abschnitt wird ein Konzept erläutert, um eine Metrik zu implementieren. Anschließend wird beschrieben, wie die Ergebnisse jeder Metrik zusammengefasst werden, um ein Endresultat zu erhalten. 

\subsection{Implementation einer Metrik}\label{chapter:metric_impl}
Damit eine Metrik die Dokumentation bewerten kann, benötigt sie Zugriff auf die Komponente. Außerdem muss sie ihr Ergebnis irgendwie veröffentlichen bzw. zwischenspeichern, damit es später weiterverarbeitet werden kann. Des Weiteren ist nicht jede Metrik mit jede Komponente kompatibel. Eine Metrik, die überprüft, ob jeder Methodenparameter dokumentiert ist (vgl. Kapitel \ref{chapter:method_doc}), kann mit anderen Komponentenarten weniger anfangen. Zudem sollte es die Möglichkeit geben, das Verhalten einer Metrik mittels Parameter anzupassen, damit die Metrik konfigurierbar bleibt. Zuletzt sollte eine Metrik bei der Bewertung auch begründen, warum die Dokumentation einer Komponente nicht ausreichend ist.

Eine Möglichkeit, diese Anforderung für eine Metrik umzusetzen, wäre die Verwendung einer Methode pro Metrik, welche die Komponente und die Parameter als Eingabe erhält und daraus die Bewertung und eventuelle Begründung ermittelt und zurückgibt. Allerdings ist dieser Ansatz sehr prozedural; es gibt beispielsweise keine Kapselung zwischen den Metriken.  

Ein anderer Ansatz, der hier auch gewählt wird, ist es, jede gewünschte Metrik als Klasse zu implementieren. Jede implementierte Metrik kann somit die notwendigen Berechnungen abgekapselt von anderen Metriken erledigen, was die Wartbarkeit verbessert. Um trotzdem für eine einheitliche Schnittstelle zu sorgen, muss jede zu implementierende Metrik von einer abstrakten Basisklasse \textit{(DocumentationAnalysisMetric)} erben,, welche die Implementation bestimmter Methoden vorschreibt, sodass ein Benutzer der Metrik auch ohne Wissen über die Interna der Metrik diese verwenden kann. Die Methode \textit{shallConsider} überprüft, ob eine Komponente für diese Metrik ist geeignet ist und gibt dementsprechend einen Wahrheitswert zurück. Die Methode \textit{analyze} führt anschließend die Bewertung durch.

Zudem kann ein Objekt, das eine Metrik repräsentiert und daher von \textit{DocumentationAnalysisMetric} erbt (Metrikobjekt), Parameter besitzen, welche spezifische Eigenschaften der Metrik modifizieren kann. Diese Eigenschaft werden sehr abhängig von der Metrik sein, sodass eine einheitliche Schnittstelle nur schwer umsetzbar ist. Daher werden die Parameter als Datentyp \textit{any} übergeben, sodass es keine Typüberprüfung gibt. Alternativ wäre eine assoziative Liste möglich, bei dem ein Parametername als Zeichenketter ein Wert zugeordnet wird, aber auch hier könnte kein Überprüfung eines Datentypes vorgenommen werden. 

Eine  weitere Voraussetzung für ein Metrikobjekt ist ein eindeutiger Name. Dadurch kann die gleiche Metrik mit unterschiedlichen Parametern verwendet werden. Außerdem wird so eine Zuordnung von Gewichten vereinfacht. Standardmäßig besteht dieser eindeutige Name aus dem Namen der implementierten Metrik gefolgt von einem Unterstrich und einer fortlaufenden Nummer.
\subsubsection{Bewertung der Dokumentation}
Die Methode \textit{analyze} muss eine Bewertung darüber abgeben, ob die Qualität der Dokumentation ausreichend ist. Für die Repräsentation dieser Bewertung gibt es viele Möglichkeiten, allerdings ist eine numerische Bewertung mittels einer Intervallskala am sinnvollsten, da so der arithmetische Mittelwert, der Median etc. berechnet werden kann, was für die Bildung des Gesamtergebnisses wichtig ist.
Die numerische Bewertung soll eine Aussage über die Dokumentationsqualität liefern. Eine Bewertung von 0 steht für eine sehr schlechte bis nicht existente Dokumentation und die Bewertung 100 steht für eine exzellente Dokumentation, sodass die Bewertung sich als Prozent lesen lassen kann. Das Ergebnis einer implementierten Metrik sollte diesen Wertebereich nicht verlassen, da eine Fehlerbehandlung nicht implementiert ist. Bei Metriken, die per Design schon eine prozentualen Wert zurückgeben (z.~B. \ref{chapter:metrics_simple_comment}) wird diese Vorgabe stets eingehalten. Bei anderen Metriken (z.~B. \ref{chapter:metrics_flesh}) sollte eine mathematische Funktion gefunden werden, die das Ergebnis der Metrik auf den Wertebereich 0 bis 100 abbildet. Die genaue Umsetzung hängt von der Metrik ab. In jedem Falle sollte es für eine Metrik Ergebnisse geben, die auf eine gute bzw. schlechte Dokumentation hindeuten, damit diese auf 100 bzw. 0 abgebildet werden können. Nur durch diese Einschränkung auf einen fixen Wertebereich ist es möglich, den Mittelwert, Median etc. zu bilden und so eine Vergleichbarkeit zu ermöglichen. 

\subsection{Ergebnis der Metrik verarbeiten}

Das berechnete Ergebnis einer Komponente muss nun gespeichert werden, damit es später ausgewertet werden kann. Dazu wird ein \textit{MetricResult}-Objekt erstellt, welches das im vorherigen Unterabschnitt berechnet Ergebnis enthält. Außerdem werden hier eventuelle Begründungen und Hinweise gespeichert, die dem Anwender dabei unterstützen, die Qualität der Dokumentation zu verbessern. Jede Begründung enthält den Dateipfad der betroffenen Datei, die bemängelte Komponente und die Zeilennummer, sodass der Benutzer die problematische Stelle schnell finden kann. Zuletzt wird außerdem eine Zeichenkette gespeichert, die später für die Gewichtung relevant ist. 

Für die Speicherung des Objekt gibt es zwei Möglichkeiten. Die erste Möglichkeit wäre es, dass die \textit{analyze}-Methode das \textit{MetricResult}-Objekt einfach zurückgibt, sodass der Aufrufer damit arbeiten kann. Bei der zweiten Möglichkeit wird das Ergebnis einem anderen Objekt übergeben, der dann die Weiterverarbeitung vornimmt. Dies hat den Vorteil, dass eine Metrik kein Ergebnis zurückliefern muss, wenn es kein sinnvolles Ergebnis berechnen kann. Bei einem Rückgabewert müsste dann ein ungültiger Wert wie z.~B. \textit{null} vereinbart werden. Außerdem kann eine Metrik auch mehrere Resultate speichern, was bei komplexeren Komponenten interessant sein dürfte. Dieses weitere Objekt ist ein  \textit{MetricResultBuilder}, der wie in nächsten Unterabschnitt beschrieben, die Softwaredokumentationsqualität jeder Komponente sammelt und daraus ein Gesamtergebnis berechnet.  
\subsection{Resultate der Metriken anwenden}
Da in einer Datei mehrere Komponenten durchaus Standard sind (eine Klasse mit einer enthaltener Methode zählt bspw. als zwei Komponenten), müssen die Bewertungen jeder Komponente passend aggregiert werden. Dazu wird dem \textit{MetricResultBuilder} jedes Ergebnis mittels der \textit{processResult}-Methode mitgeteilt, welches das Ergebnis in einer Liste speichert. Wenn alle Metriken verarbeitet sind, wird daraus ein Gesamtresultat gebildet. Dies geschieht durch die Methode \textit{getAggregratedResult}. Dabei wird standardmäßig ein arithmetischer Mittelwert gebildet. Durch Ableitung kann diese Methode überschrieben werden, um den Median oder eine Gewichtung bei der Bildung des Gesamtergebnisses zu verwenden  sodass die Wahl des Algorithmus flexibel bleibt . Ein \textit{ResultBuilder} basiert auf dem Vorbild des Design-Patterns \enquote{Builder} aus \cite[S.139-149]{gamma2015design}, da es aus einzelnen Metrikresultaten ein vollständiges Metrikergebnis baut.

Abbildung \ref{fig:metrics_apply} zeigt schematisch, wie aus verschiedenen Dateien ein Gesamtergebnis ausgebaut wird. Hier werden zwei Dateien und zwei exemplarische Metriken verwendet. Links unten wird die erste Datei (rot) durch der ersten Metrik bewertet. Dazu wird ein interner \textit{MetricResultBuilder} verwendet, was aber hier aus Übersichtlichkeitsgründen nicht dargestellt wird. Auch die zweite Metrik bewertet die gleiche Datei, sodass von beiden Metriken ein Ergebnis vorliegt. Diese Ergebnisse werden von einem \textit{MetricResultBuilder} verarbeiten, der beispielsweise die Ergebnisse je nach Metrik gewichten kann. Das Ergebnis dieses Vorgangs wird von einem separaten \textit{MetricResultBuilder} verarbeitet, welcher dieses und das Ergebnis der zweiten Datei (grün), das analog ermittelt wird, verarbeitet und und eine Gewichtung nach Dateipfad vornehmen könnte. Das Gesamtergebnis oben in der Mitte ist dann Maß für die Entscheidung, ob die Dokumentationsqualität als ausreichend angesehen wird. 
\begin{figure}[ht!]
\fontsize{7}{10}\selectfont
    \centering
\includesvg[scale=0.5]{figures/metrics.svg}
    \caption{Anwendung der Metriken}
    \label{fig:metrics_apply}
\end{figure}
 
\subsection{Zuordnung der Gewichte}\label{chapter_weights_assign}
Für einige Algorithmen muss eine Gewichtung vorgenommen werden, um bestimmte Ergebnisse besser oder schlechter zu bewerten. Dazu muss jedes Teilergebnis eine Gewicht zugeordnet werden. Ein Teilergebnis, das gewichtet werden soll, kann hier entweder von einer einzelnen Metrik oder einer einzelnen Datei produziert werden. Im Falle einer Datei existiert durch den Dateipfad ein eindeutiger Name. Auch bei einer Metrik wird dies durch die Konzeption in Kapitel \ref{chapter:metric_impl} sichergestellt. Die Zuordnung erfolgt über einen \textit{WeightResolver}, welches eine Schnittstelle anbietet, um einen Bezeichner auf ein Gewicht abzubilden. Bei dem eindeutigen Namen eines Metrikobjektes kann hierfür eine assoziative Liste verwendet werden. 
Für Dateipfade ist dies allerdings nicht praktikabel, da es eine Vielzahl an Dateien geben kann. Stattdessen werden hier ähnlich wie bei der Filterung von Dateien in Kapitel \ref{chapter:traversing} Wildcard-Patterns verwendet. Eine assoziative Liste speichert dazu jedes Wildcard-Patterns und das dazugehörige Gewicht. Bei einer Abfrage kann das Gewicht des ersten Eintrages zurückgegeben werden, bei dem der Dateipfad mit dem Wildcard-Patterns kompatibel ist. Dies ermöglicht es, ganze Verzeichnisse oder Dateien mit bestimmten Namen stärker zu gewichten. Für eine Datei, bei dem kein Wildcard-Pattern zutrifft, wird ein standardmäßiges Gewicht (z.~B. 1) zurückgegeben. 

Jedes \textit{MetricResult}-Objekt enthält eine Zeichenkette, die den Erzeuger des Ergebnisses repräsentiert; so kann jedes Einzelresultat passend gewichtet werden. Bei der Bildung eines Gesamtergebnis aus einzelnen Teilresultaten mittels der Methode \textit{getAggregatedResult} muss das neue \textit{MetricResult}-Objekt ebenfalls ein Erzeuger besitzen. Dieser Erzeuger wird vom Anwender der Funktion übergeben. Werden beispielsweise die Ergebnisse mehrere Metriken aber einer Datei zusammengefasst, so ist der neue Erzeuger der Dateipfad. Bei dem endgültigen Gesamtergebnis ist eine Gewichtung nicht mehr sinnvoll, daher kann dann eine leere Zeichenkette übergeben werden.

\subsection{Implementierte Algorithmen zur Bildung eines Gesamtergebnisses}
In den folgenden Unterabschnitten wird jeder Algorithmus, welches ein Gesamtresultat bildet, kurz erläutert und dabei kurz auf die Vor- und Nachteile eingegangen. 

\subsubsection{Arithmetischer Mittelwert}
Der arithmetische Mittelwert wird bereits durch die Klasse \textit{MetricResultBuilder} implementiert. Dieser Algorithmus berücksichtigt jedes Ergebnis gleichermaßen. Dies ist insbesondere für die Aggregierung der Ergebnisse der einzelnen Dateien sinnvoll, da jede Datei gleich behandelt werden sollte und eine Gewichtung von möglicherweise Tausenden von Dateien nur schwer umsetzbar ist. Es sollte allerdings auch beachtet werden, dass der Mittelwert extreme Ausreißer berücksichtigt. Dies ist hier manchmal sinnvoll, da sehr schlechte Dokumentation besser berücksichtigt wird und so ein verlässliches Gesamtergebnis geliefert wird.


\subsubsection{Median}
Der Median der Einzelresultate wird von der Klasse \textit{MedianResultBuilder} berechnet. Dabei werden die Einzelresultate nach den bekannten Median-Algorithmus verarbeitet. Bei einer geraden Anzahl an Elementen wird der Median aus dem Mittelwert der zwei infrage kommenden Ergebnissen gebildet. 

Der Median berücksichtigt einzelne Ausreißer nicht und kann daher interessant sein, wenn ein allgemeines Bild von der Dokumentationsqualität erhalten werden soll. Es sollte aber beachtet werden, dass die Anwendung des Medians ein Sortiervorgang benötigt, der in den meisten Fällen eine Komplexität von $O(n*log(n))$ hat. Bei der überschaubaren Anzahl an Metriken wird dies weniger relevant sein, bei einer Anwendung des Medians auf vielen Dateien durchaus wohl.


\subsubsection{Gewichteter Mittelwert}
Der gewichtete Mittelwert ist in der Klasse \textit{WeightedMetricResultBuilder} implementiert. Die Zuweisung der Gewichte erfolgt wie in Kapitel \ref{chapter_weights_assign} beschrieben durch einen \textit{WeightResolver}. Die Gewichte müssen nicht normiert werden, da dies während der Berechnung implizit erledigt wird. Die Resultate jeder Metrik werden multipliziert mit dessen Gewicht, dann aufsummiert und zuletzt durch die Summe aller Gewichte geteilt. 


Dieser Algorithmus ermöglicht es, bestimmte Metriken zu bevorzugen bzw. zu benachteiligen. Dies ist sinnvoll, da nicht jede Metrik immer ein aussagekräftiges Ergebnis liefert und bestimmte Metriken je nach Situation ein besseres Bild über die Dokumentationsqualität liefern. Allerdings ist auch zu beachten, dass die Wahl der Gewichte nicht trivial ist und ein Vergleich von Ergebnissen, die verschiedene Gewichte verwenden, nicht sinnvoll ist.

\subsubsection{Gewichteter Median}
Der gewichtete Median wurde leicht abweichend nach \cite[S. 37]{YAGER199835} implementiert. Dabei wird zunächst die Summe der Gewichte berechnet und die Resultate nach ihrem Gewicht sortiert. Anschließend werden die sortierten Resultate und ihre Gewichte so lange aufsummiert, bis diese temporäre Summe die Hälfte der Gesamtsumme überschreitet. Das Metrikergebnis, bei der diese Bedingung zutrifft, ist das gesuchte Gesamtergebnis. Die Vor- und Nachteile dieses Algorithmus entsprechen den Vor- und Nachteilen des gewichteten Mittelwerts und des Medians. So muss auch hier eine Sortierung durchgeführt werden und die Wahl der richtigen Gewichte ist nicht trivial. 


