% Encoding: UTF-8

@InProceedings{AutomaticQualityAssessmentofSourceCodeComments:TheJavadocMiner,
  author    = {Khamis, Ninus and Witte, Ren{\'e} and Rilling, Juergen},
  title     = {Automatic Quality Assessment of Source Code Comments: The JavadocMiner},
  booktitle = {Natural Language Processing and Information Systems},
  year      = {2010},
  editor    = {Hopfe, Christina J. and Rezgui, Yacine and M{\'e}tais, Elisabeth and Preece, Alun and Li, Haijiang},
  publisher = {Springer Berlin Heidelberg},
  isbn      = {978-3-642-13881-2},
  pages     = {68--79},
  abstract  = {An important software engineering artefact used by developers and maintainers to assist in software comprehension and maintenance is source code documentation. It provides insights that help software engineers to effectively perform their tasks, and therefore ensuring the quality of the documentation is extremely important. Inline documentation is at the forefront of explaining a programmer's original intentions for a given implementation. Since this documentation is written in natural language, ensuring its quality needs to be performed manually. In this paper, we present an effective and automated approach for assessing the quality of inline documentation using a set of heuristics, targeting both quality of language and consistency between source code and its comments. We apply our tool to the different modules of two open source applications (ArgoUML and Eclipse), and correlate the results returned by the analysis with bug defects reported for the individual modules in order to determine connections between documentation and code quality.},
  address   = {Berlin, Heidelberg},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/2010_Book_NaturalLanguageProcessingAndIn.pdf:PDF},
}

@Article{SoftwareDocumentationManagementIssuesandPractices:ASurvey,
  author  = {C J, Satish and Mahendran, Anand},
  title   = {Software Documentation Management Issues and Practices: A Survey},
  journal = {Indian Journal of Science and Technology},
  year    = {2016},
  volume  = {9},
  month   = {05},
  doi     = {10.17485/ijst/2016/v9i20/86869},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Article50.pdf:PDF},
}

@InProceedings{Qualityanalysisofsourcecodecomments,
  author    = {Steidl, Daniela and Hummel, Benjamin and Juergens, Elmar},
  title     = {Quality analysis of source code comments},
  booktitle = {2013 21st International Conference on Program Comprehension (ICPC)},
  year      = {2013},
  pages     = {83-92},
  doi       = {10.1109/ICPC.2013.6613836},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Quality_analysis_of_source_code_comments.pdf:PDF},
}

@WWW{PMD,
  title = {PMD},
  date  = {2021-10-20},
  url   = {https://pmd.github.io/},
}

@WWW{Checkstyle,
  title    = {Checkstyle},
  date     = {2021-10-20},
  url      = {https://checkstyle.sourceforge.io/},

}
@misc{treude2020accuracy,
      title={Beyond Accuracy: Assessing Software Documentation Quality}, 
      author={Christoph Treude and Justin Middleton and Thushari Atapattu},
      year={2020},
      eprint={2007.10744},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}
@WWW{ANTLR,
  title = {ANTLR},
  date  = {2021-10-20},
  url   = {https://www.antlr.org/},
}

@WWW{GithubActions,
  title = {Github Actions},
  date  = {2021-10-20},
  url   = {https://docs.github.com/en/actions},
}

@WWW{ANTLRgrammarforjava,
  title = {ANTLR grammar for java},
  date  = {2021-10-20},
  url   = {https://github.com/antlr/grammars-v4/tree/master/java},
}

@InProceedings{EvaluatingtheQualityoftheDocumentationofOpenSourceSoftware,
  author    = {Lerina Aversano and Daniela Guardabascio and Maria Tortorella},
  title     = {Evaluating the Quality of the Documentation of Open Source Software},
  booktitle = {ENASE},
  year      = {2017},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/f3f43b0c19d7a73db0f78b10bfa2b411f341.pdf:PDF},
}

@Article{Qualitycontrolinsoftwaredocumentationbasedonmeasurementoftextcomprehensionandtextcomprehensibility,
  author   = {Franz Lehner},
  title    = {Quality control in software documentation based on measurement of text comprehension and text comprehensibility},
  journal  = {Information Processing \& Management},
  year     = {1993},
  volume   = {29},
  number   = {5},
  pages    = {551-568},
  issn     = {0306-4573},
  doi      = {https://doi.org/10.1016/0306-4573(93)90079-S},
  url      = {https://www.sciencedirect.com/science/article/pii/030645739390079S},
  abstract = {The importance of software documentation and the effects of poor documentation in data processing are often underrated. Little research has been published that evaluates the quality of software documentation. The evaluation of textual attributes such as comprehensibility, readability, etc., has seen more studies and relatively sound results. Thus this paper exclusively handles textual documentation, whereby the methods are employed for the evaluation of software documentation. We first introduce the methods used in the measurement of text comprehensibility. Then RMS (Readability Measuring System), a tool developed by the author to support the measuring process, is presented. The third part of the paper presents empirical results and discusses the experience gained in the application of the RMS tool.},
  file     = {:/home/compf/data/uni/sem7/bachelor/sources/1-s2.0-030645739390079S-main.pdf:PDF},
}

@InProceedings{TheValueofSoftwareDocumentationQuality,
  author    = {Plösch, Reinhold and Dautovic, Andreas and Saft, Matthias},
  title     = {The Value of Software Documentation Quality},
  booktitle = {2014 14th International Conference on Quality Software},
  year      = {2014},
  pages     = {333-342},
  doi       = {10.1109/QSIC.2014.22},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/The_Value_of_Software_Documentation_Quality.pdf:PDF},
}

@InProceedings{SoftwareDocumentationIssuesUnveiled,
  author    = {Aghajani, Emad and Nagy, Csaba and Vega-Márquez, Olga Lucero and Linares-Vásquez, Mario and Moreno, Laura and Bavota, Gabriele and Lanza, Michele},
  title     = {Software Documentation Issues Unveiled},
  booktitle = {2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)},
  year      = {2019},
  pages     = {1199-1210},
  doi       = {10.1109/ICSE.2019.00122},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Software_Documentation_Issues_Unveiled.pdf:PDF},
}

@InProceedings{OpenSourceSoftwareDocumentationMiningforQualityAssessment,
  author    = {Nuno Ramos Carvalho and Alberto Sim{\~o}es and Jos{\'e} Jo{\~a}o Almeida},
  title     = {Open Source Software Documentation Mining for Quality Assessment},
  booktitle = {WorldCIST},
  year      = {2013},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/wcist2012-dmoss.pdf:PDF},
}

@Article{RecoveringTraceabilityLinksbetweenCodeandDocumentation,
  author  = {Antoniol, Giuliano and Canfora, Gerardo and Casazza, Gerardo and Lucia, Andrea and Merlo, Ettore},
  title   = {Recovering Traceability Links between Code and Documentation},
  journal = {Software Engineering, IEEE Transactions on},
  year    = {2002},
  volume  = {28},
  month   = {11},
  pages   = {970- 983},
  doi     = {10.1109/TSE.2002.1041053},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Antoniol02a.pdf:PDF},
}

@Article{AutomatedEvaluationofSourceCodeDocumentation:InterimReport,
  author = {Hirsch, Ben and Heines, Jesse},
  title  = {Automated Evaluation of Source Code Documentation: Interim Report},
  year   = {2008},
  month  = {07},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/Automated_Evaluation_of_Source_Code_Documentation_.pdf:PDF},
}

@Article{ANTLR:APredicated-<i>LLk</i>ParserGenerator,
  author     = {Parr, T. J. and Quong, R. W.},
  title      = {ANTLR: A Predicated-<i>LL(k)</i> Parser Generator},
  journal    = {Softw. Pract. Exper.},
  year       = {1995},
  volume     = {25},
  number     = {7},
  month      = jul,
  pages      = {789–810},
  issn       = {0038-0644},
  doi        = {10.1002/spe.4380250705},
  url        = {https://doi.org/10.1002/spe.4380250705},
  address    = {USA},
  file       = {:/home/compf/data/uni/sem7/bachelor/sources/10.1.1.57.881.pdf:PDF},
  issue_date = {July 1995},
  keywords   = {parsing, parser generator, compiler, predicates, LL(k) parser},
  numpages   = {22},
  publisher  = {John Wiley \&amp; Sons, Inc.},
}

@Article{ComparativeStudyoftheQualityAssessmentToolsBasedonaModel:SonarSqualeEvalMetrics,
  author  = {Bougroun, Zineb and Zeaaraoui, Adil and Toumi, Bouchentouf},
  title   = {Comparative Study of the Quality Assessment Tools Based on a Model: Sonar, Squale, EvalMetrics},
  journal = {Journal of Computer Science},
  year    = {2016},
  volume  = {12},
  month   = {01},
  pages   = {39-47},
  doi     = {10.3844/jcssp.2016.39.47},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/52-Article Text-100-1-10-20210516.pdf:PDF},
}

@InProceedings{Automaticassessmentofsoftwaredocumentationquality,
  author    = {Dautovic, Andreas},
  title     = {Automatic assessment of software documentation quality},
  booktitle = {2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011)},
  year      = {2011},
  pages     = {665-669},
  doi       = {10.1109/ASE.2011.6100151},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Automatic_assessment_of_software_documentation_quality.pdf:PDF},
}

@Article{DMOSS:Opensourcesoftwaredocumentationassessment,
  author  = {Nuno Ramos Carvalho and Alberto Sim{\~o}es and Jos{\'e} Jo{\~a}o Almeida},
  title   = {DMOSS: Open source software documentation assessment},
  journal = {Comput. Sci. Inf. Syst.},
  year    = {2014},
  volume  = {11},
  pages   = {1197-1207},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/dmoss.pdf:PDF},
}

@Article{Softwaredocumentation,
  author  = {Sommerville, Ian},
  title   = {Software documentation},
  journal = {Software engineering},
  year    = {2001},
  volume  = {2},
  pages   = {143--154},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/documentation.pdf:PDF},
}

@InProceedings{HowDocumentationEvolvesoverTime,
  author    = {Schreck, Daniel and Dallmeier, Valentin and Zimmermann, Thomas},
  title     = {How Documentation Evolves over Time},
  booktitle = {Ninth International Workshop on Principles of Software Evolution: In Conjunction with the 6th ESEC/FSE Joint Meeting},
  year      = {2007},
  series    = {IWPSE '07},
  publisher = {Association for Computing Machinery},
  location  = {Dubrovnik, Croatia},
  isbn      = {9781595937223},
  pages     = {4–10},
  doi       = {10.1145/1294948.1294952},
  url       = {https://doi.org/10.1145/1294948.1294952},
  abstract  = {Good source code documentation, especially of programming interfaces, is essential
for using and maintaining software components. In this paper, we present the Quasoledo
tool that automatically measures the quality of documentation with respect to completeness,
quantity, and readability. We applied our set of metrics to the Eclipse project, and
benchmarked against the well-documented Java class library. The result of Quasoledo
is a map of documentation quality in Eclipse, showing the best documentation for its
core components. Additionally, we looked at the evolution of Eclipse and identified
batch updates that caused jumps in documentation quality. For Eclipse, only 32.6\%
of all changes touched documentation.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/1294948.1294952.pdf:PDF},
  numpages  = {7},
}

@Article{SMSCQA:SystemforMeasuringSourceCodeQualityAssurance,
  author  = {Ayman, Hussein and Odeh, Ayman},
  title   = {SMSCQA: System for Measuring Source Code Quality Assurance},
  journal = {International Journal of Computer Applications},
  year    = {2012},
  volume  = {60},
  month   = {12},
  pages   = {975-8887},
  doi     = {10.5120/9714-4181},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/10.1.1.303.4758.pdf:PDF},
}

@InProceedings{JavadocViolationsandTheirEvolutioninOpen-SourceSoftware,
  author    = {Steinbeck, Marcel and Koschke, Rainer},
  title     = {Javadoc Violations and Their Evolution in Open-Source Software},
  booktitle = {2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  year      = {2021},
  pages     = {249-259},
  doi       = {10.1109/SANER50967.2021.00031},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Javadoc_Violations_and_Their_Evolution_in_Open-Source_Software.pdf:PDF},
}

@InProceedings{Exstatic:AGenericStaticCheckerAppliedtoDocumentationSystems,
  author    = {Mount, S. N. I. and Newman, R. M. and Low, R. J. and Mycroft, A.},
  title     = {Exstatic: A Generic Static Checker Applied to Documentation Systems},
  booktitle = {Proceedings of the 22nd Annual International Conference on Design of Communication: The Engineering of Quality Documentation},
  year      = {2004},
  series    = {SIGDOC '04},
  publisher = {Association for Computing Machinery},
  location  = {Memphis, Tennessee, USA},
  isbn      = {1581138091},
  pages     = {52–57},
  doi       = {10.1145/1026533.1026548},
  url       = {https://doi.org/10.1145/1026533.1026548},
  abstract  = {Exstatic is a generic static checker developed by the author to address many of the
practical problems in program development. Static checking provides a valuable means
for automating time consuming checks not only concerned with program correctness (writing
the right program), but also to do with style (writing the program right). Previous
static checkers have been closely coupled with compilation systems, and therefore
tend to be applicable to the code itself and not to all of the textual information
(such as makefiles, comments, documentation sources) surrounding the code. The generic
nature of Exstatic allows it to overcome these boundaries, and indeed it can be applied
to any medium for which there is a formally definable syntax and (to an extent) semantics.
Exstatic can therefore be used to increase the productivity and quality of documentation
of programs, checking for such things as adherence to house style, consistency with
the program being documented and self consistency. This paper describes the design
and use of Exstatic, with particular reference to its use in documentation systems.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/1026533.1026548.pdf:PDF},
  keywords  = {static checking, standards, javadoc, exstatic, docstrings},
  numpages  = {6},
}

@InProceedings{@tComment:TestingJavadocCommentstoDetectComment-CodeInconsistencies,
  author  = {Tan, Shin Hwei and Marinov, Darko and Tan, Lin and Leavens, Gary},
  title   = {@tComment: Testing Javadoc Comments to Detect Comment-Code Inconsistencies},
  year    = {2012},
  volume  = {abs/1201.6078},
  month   = {04},
  doi     = {10.1109/ICST.2012.106},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/tComment-icst12.pdf:PDF},
  journal = {CoRR},
}

@Article{ImplementingSourceCodeMetricsforSoftwarequalityanalysis,
  author  = {Mandeep K. Chawla and Indu Chhabra},
  title   = {Implementing Source Code Metrics for Software quality analysis},
  journal = {International journal of engineering research and technology},
  year    = {2012},
  volume  = {1},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/implementing-source-code-metrics-for-software-quality-analysis-IJERTV1IS5099.pdf:PDF},
}

@Article{CommentingonCodeConsideringDatasBottleneck,
  author     = {Torres, Edwin and Saba, Walid},
  title      = {Commenting on Code, Considering Data's Bottleneck},
  journal    = {Commun. ACM},
  year       = {2018},
  volume     = {61},
  number     = {5},
  month      = apr,
  pages      = {24–25},
  issn       = {0001-0782},
  doi        = {10.1145/3193752},
  url        = {https://doi.org/10.1145/3193752},
  abstract   = {The Communications Web site, http://cacm.acm.org, features more than a dozen bloggers
in the BLOG@CACM community. In each issue of Communications, we'll publish selected
posts or excerpts.twitterFollow us on Twitter at http://twitter.com/blogCACMhttp://cacm.acm.org/blogs/blog-cacmEdwin
Torres considers the enduring value of code comments, while Walid Saba wonders if
we have overreacted to the knowledge acquisition bottleneck.},
  address    = {New York, NY, USA},
  file       = {:/home/compf/data/uni/sem7/bachelor/sources/3193752.pdf:PDF},
  issue_date = {May 2018},
  numpages   = {2},
  publisher  = {Association for Computing Machinery},
}

@Article{StaticAnalysis:AnIntroduction:TheFundamentalChallengeofSoftwareEngineeringisOneofComplexity.,
  author     = {Thomson, Patrick},
  title      = {Static Analysis: An Introduction: The Fundamental Challenge of Software Engineering is One of Complexity.},
  journal    = {Queue},
  year       = {2021},
  volume     = {19},
  number     = {4},
  month      = aug,
  pages      = {29–41},
  issn       = {1542-7730},
  doi        = {10.1145/3487019.3487021},
  url        = {https://doi.org/10.1145/3487019.3487021},
  abstract   = {Modern static-analysis tools provide powerful and specific insights into codebases.
The Linux kernel team, for example, developed Coccinelle, a powerful tool for searching,
analyzing, and rewriting C source code; because the Linux kernel contains more than
27 million lines of code, a static-analysis tool is essential both for finding bugs
and for making automated changes across its many libraries and modules. Another tool
targeted at the C family of languages is Clang scan-build, which comes with many useful
analyses and provides an API for programmers to write their own analyses. Like so
many things in computer science, the utility of static analysis is self-referential:
To write reliable programs, we must also write programs for our programs. But this
is no paradox. Static-analysis tools, complex though their theory and practice may
be, are what will enable us, and engineers of the future, to overcome this challenge
and yield the knowledge and insights that we practitioners deserve.},
  address    = {New York, NY, USA},
  file       = {:/home/compf/data/uni/sem7/bachelor/sources/3487019.3487021.pdf:PDF},
  issue_date = {July-August 2021},
  numpages   = {13},
  publisher  = {Association for Computing Machinery},
}

@Article{DocumentationTesting,
  author     = {Mamone, Salvatore},
  title      = {Documentation Testing},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {2000},
  volume     = {25},
  number     = {2},
  month      = mar,
  pages      = {26–29},
  issn       = {0163-5948},
  doi        = {10.1145/346057.346066},
  url        = {https://doi.org/10.1145/346057.346066},
  abstract   = {One definition of documentation is 'Any written or pictorial information describing,
defining, specifying, reporting, or certifying activities, requirements, procedures,
or results.' (1). Documentation is as important to a product's success as the product
itself. If the documentation is poor, non-existent, or wrong, it reflects on the quality
of the product and the vendor.At the Bell Atlantic Systems Integration &amp; Testing
Center documentation testing is an important function that receives as much attention
as the testing of software and hardware. Because the Bell Atlantic Systems Integration
&amp; Testing Center is ISO9001 certified, an enormous effort was undertaken to ensure
quality assurance of all products including documentation. Both a test procedure and
test plan for documentation has been implemented to ensure this quality.This article
will describe what documentation is, why document testing is important, and how document
testing is performed at the Bell Atlantic Systems Integration &amp; Testing Center.Other
information pertaining to documentation, such as human factors, how to achieve document
comprehensiveness, and comprehensibility, although important, are beyond the reach
of this report.},
  address    = {New York, NY, USA},
  file       = {:/home/compf/data/uni/sem7/bachelor/sources/346057.346066.pdf:PDF},
  issue_date = {March 2000},
  numpages   = {4},
  publisher  = {Association for Computing Machinery},
}

@Article{IEEEStandardGlossaryofSoftwareEngineeringTerminology,
  title   = {IEEE Standard Glossary of Software Engineering Terminology},
  journal = {IEEE Std 610.12-1990},
  year    = {1990},
  pages   = {1-84},
  doi     = {10.1109/IEEESTD.1990.101064},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/61012-1990.pdf:PDF},
}

@Article{Softwaredocumentation:frominstructiontointegration,
  author  = {Barker, T.T.},
  title   = {Software documentation: from instruction to integration},
  journal = {IEEE Transactions on Professional Communication},
  year    = {1990},
  volume  = {33},
  number  = {4},
  pages   = {172-177},
  doi     = {10.1109/47.62811},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Software_documentation_from_instruction_to_integration.pdf:PDF},
}

@Article{Softwaredocumentationandstandards,
  author  = {J. M. Jose and T. Viswanathan},
  title   = {Software documentation and standards},
  journal = {Annals of library science and documentation},
  year    = {1992},
  volume  = {39},
  pages   = {123-133},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/ALIS 39(4) 123-133.pdf:PDF},
}

@InProceedings{TheRelevanceofSoftwareDocumentationToolsandTechnologies:ASurvey,
  author    = {Forward, Andrew and Lethbridge, Timothy C.},
  title     = {The Relevance of Software Documentation, Tools and Technologies: A Survey},
  booktitle = {Proceedings of the 2002 ACM Symposium on Document Engineering},
  year      = {2002},
  series    = {DocEng '02},
  publisher = {Association for Computing Machinery},
  location  = {McLean, Virginia, USA},
  isbn      = {1581135947},
  pages     = {26–33},
  doi       = {10.1145/585058.585065},
  url       = {https://doi.org/10.1145/585058.585065},
  abstract  = {This paper highlights the results of a survey of software professionals. One of the
goals of this survey was to uncover the perceived relevance (or lack thereof) of software
documentation, and the tools and technologies used to maintain, verify and validate
such documents. The survey results highlight the preferences for and aversions against
software documentation tools. Participants agree that documentation tools should seek
to better extract knowledge from core resources. These resources include the system's
source code, test code and changes to both. Resulting technologies could then help
reduce the effort required for documentation maintenance, something that is shown
to rarely occur. Our data reports compelling evidence that software professionals
value technologies that improve automation of the documentation process, as well as
facilitating its maintenance.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/585058.585065.pdf:PDF},
  keywords  = {software maintenance, software documentation, program comprehension, documentation survey, documentation technologies, documentation relevance, software engineering},
  numpages  = {8},
}

@Article{CostBenefitsandQualityofSoftwareDevelopmentDocumentation:ASystematicMapping,
  author  = {Zhi, Junji and Garousi, Vahid and Sun, Bo and Garousi, Golara and Shahnewaz, S. and Ruhe, Guenther},
  title   = {Cost, Benefits and Quality of Software Development Documentation: A Systematic Mapping},
  journal = {Journal of Systems and Software},
  year    = {2014},
  volume  = {99},
  month   = {01},
  doi     = {10.1016/j.jss.2014.09.042},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Cost Benefits and Quality of Software Development.pdf:PDF},
}

@WWW{Javadoc,
  title   = {Javadoc},
  url     = {https://www.oracle.com/technical-resources/articles/java/javadoc-tool.html},
  urldate = {2021-10-21},
}

@Misc{BeyondAccuracy:AssessingSoftwareDocumentationQuality,
  author        = {Christoph Treude and Justin Middleton and Thushari Atapattu},
  title         = {Beyond Accuracy: Assessing Software Documentation Quality},
  year          = {2020},
  eprint        = {2007.10744},
  archiveprefix = {arXiv},
  file          = {:/home/compf/data/uni/sem7/bachelor/sources/2007.10744.pdf:PDF},
  primaryclass  = {cs.SE},
}

@Misc{kuhn2013verifiable,
  author        = {Tobias Kuhn and Alexandre Bergel},
  title         = {Verifiable Source Code Documentation in Controlled Natural Language},
  year          = {2013},
  eprint        = {1311.2702},
  archiveprefix = {arXiv},
  file          = {:/home/compf/data/uni/sem7/bachelor/sources/1311.2702.pdf:PDF},
  primaryclass  = {cs.SE},
}

@InProceedings{10.1145/944868.944888,
  author    = {Huang, Shihong and Tilley, Scott},
  title     = {Towards a Documentation Maturity Model},
  booktitle = {Proceedings of the 21st Annual International Conference on Documentation},
  year      = {2003},
  series    = {SIGDOC '03},
  publisher = {Association for Computing Machinery},
  location  = {San Francisco, CA, USA},
  isbn      = {158113696X},
  pages     = {93–99},
  doi       = {10.1145/944868.944888},
  url       = {https://doi.org/10.1145/944868.944888},
  abstract  = {This paper presents preliminary work towards a maturity model for system documentation. The Documentation Maturity Model (DMM) is specifically targeted towards assessing the quality of documentation used in aiding program understanding. Software engineers and technical writers produce such documentation during regular product development lifecycles. The documentation can also be recreated after the fact via reverse engineering. The DMM has both process and product components; this paper focuses on the product quality aspects.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/944868.944888.pdf:PDF},
  keywords  = {documentation, reverse engineering, maturity model, quality},
  numpages  = {7},
}

@Article{Assessingthequalityfactorsfoundinin-linedocumentationwritteninnaturallanguage:TheJavadocMiner,
  author  = {Khamis, Ninus and Rilling, Juergen and Witte, René},
  title   = {Assessing the quality factors found in in-line documentation written in natural language: The JavadocMiner},
  journal = {Data \& Knowledge Engineering},
  year    = {2013},
  volume  = {87},
  month   = {09},
  pages   = {19–40},
  doi     = {10.1016/j.datak.2013.02.001},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/1-s2.0-S0169023X13000207-main.pdf:PDF},
}

@InProceedings{10.1145/318372.318577,
  author    = {Kramer, Douglas},
  title     = {API Documentation from Source Code Comments: A Case Study of Javadoc},
  booktitle = {Proceedings of the 17th Annual International Conference on Computer Documentation},
  year      = {1999},
  series    = {SIGDOC '99},
  publisher = {Association for Computing Machinery},
  location  = {New Orleans, Louisiana, USA},
  isbn      = {1581130724},
  pages     = {147–153},
  doi       = {10.1145/318372.318577},
  url       = {https://doi.org/10.1145/318372.318577},
  abstract  = {This paper describes in a general way the process we went through to determine the goals, principles, audience, content and style for writing comments in source code for the Java platform at the Java Software division of Sun Microsystems. This includes how the documentation comments evolved to become the home of the Java platform API specification, and the guidelines we developed to make it practical for this document to reside in the same files as the source code.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/318372.318577.pdf:PDF},
  keywords  = {doc comments, Java platform, generated documentation, doclets, source code comments, documentation comments, API documentation, Javadoc},
  numpages  = {7},
}

@Article{10.1093/comjnl/27.2.97,
  author   = {Knuth, D. E.},
  title    = {{Literate Programming}},
  journal  = {The Computer Journal},
  year     = {1984},
  volume   = {27},
  number   = {2},
  month    = {01},
  pages    = {97-111},
  issn     = {0010-4620},
  doi      = {10.1093/comjnl/27.2.97},
  eprint   = {https://academic.oup.com/comjnl/article-pdf/27/2/97/981657/270097.pdf},
  url      = {https://doi.org/10.1093/comjnl/27.2.97},
  abstract = {{The author and his associates have been experimenting for the past several years with a programming language and documentation system called WEB. This paper presents WEB by example, and discusses why the new system appears to be an improvement over previous ones.}},
  file     = {:/home/compf/data/uni/sem7/bachelor/sources/270097.pdf:PDF},
}

@InProceedings{DoclasscommentsaidJavaprogramunderstanding?,
  author = {Nurvitadhi, E. and Leung, Wing and Cook, C.},
  title  = {Do class comments aid Java program understanding?},
  year   = {2003},
  volume = {1},
  month  = {12},
  isbn   = {0-7803-7961-6},
  pages  = {T3C-13},
  doi    = {10.1109/FIE.2003.1263332},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/10.1.1.87.6694.pdf:PDF},
}

@Article{2021,
  author    = {Rani, Pooja and Panichella, Sebastiano and Leuenberger, Manuel and Ghafari, Mohammad and Nierstrasz, Oscar},
  title     = {What do class comments tell us? An investigation of comment evolution and practices in Pharo Smalltalk},
  journal   = {Empirical Software Engineering},
  year      = {2021},
  volume    = {26},
  number    = {6},
  month     = {Aug},
  issn      = {1573-7616},
  doi       = {10.1007/s10664-021-09981-5},
  url       = {http://dx.doi.org/10.1007/s10664-021-09981-5},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Rani2021_Article_WhatDoClassCommentsTellUsAnInv.pdf:PDF},
  publisher = {Springer Science and Business Media LLC},
}

@InProceedings{Softwareengineeringandsoftwaredocumentation:aunifiedlongcourse,
  author    = {Young, F.H.},
  title     = {Software engineering and software documentation: a unified long course},
  booktitle = {Proceedings Frontiers in Education Twenty-First Annual Conference. Engineering Education in a New World Order},
  year      = {1991},
  pages     = {593-595},
  doi       = {10.1109/FIE.1991.187557},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Software_engineering_and_software_documentation_a_unified_long_course.pdf:PDF},
}

@Article{TheRoleofDocumentationinProgrammerTraining-FromConventionalDocumentationtoLiterateProgrammingHypertextAndObject-OrientedDocumentation,
  author = {Sametinger, Johannes},
  title  = {The Role of Documentation in Programmer Training - From Conventional Documentation to Literate Programming, Hypertext And Object-Oriented Documentation},
  year   = {1995},
  month  = {06},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/The_Role_of_Documentation_in_Programmer_Training_-.pdf:PDF},
}

@InProceedings{10.1145/65293.71211,
  author    = {Collofello, J. S.},
  title     = {Teaching Practical Software Maintenance Skills in a Software Engineering Course},
  booktitle = {Proceedings of the Twentieth SIGCSE Technical Symposium on Computer Science Education},
  year      = {1989},
  series    = {SIGCSE '89},
  publisher = {Association for Computing Machinery},
  location  = {Louisville, Kentucky, USA},
  isbn      = {0897912985},
  pages     = {182–184},
  doi       = {10.1145/65293.71211},
  url       = {https://doi.org/10.1145/65293.71211},
  abstract  = {The typical one-semester software engineering course is normally geared towards new software development. Unfortunately, most new computer science graduates do not find themselves in a position where they are developing new software but instead in a position where they are maintaining an existing product. This paper describes some current practical software maintenance approaches which can be taught as a part of a software engineering course.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/65294.71211.pdf:PDF},
  numpages  = {3},
}

@InProceedings{10.1145/2931037.2931061,
  author    = {Goffi, Alberto and Gorla, Alessandra and Ernst, Michael D. and Pezz\`{e}, Mauro},
  title     = {Automatic Generation of Oracles for Exceptional Behaviors},
  booktitle = {Proceedings of the 25th International Symposium on Software Testing and Analysis},
  year      = {2016},
  series    = {ISSTA 2016},
  publisher = {Association for Computing Machinery},
  location  = {Saarbr\"{u}cken, Germany},
  isbn      = {9781450343909},
  pages     = {213–224},
  doi       = {10.1145/2931037.2931061},
  url       = {https://doi.org/10.1145/2931037.2931061},
  abstract  = { Test suites should test exceptional behavior to detect faults in error-handling code. However, manually-written test suites tend to neglect exceptional behavior. Automatically-generated test suites, on the other hand, lack test oracles that verify whether runtime exceptions are the expected behavior of the code under test.  This paper proposes a technique that automatically creates test oracles for exceptional behaviors from Javadoc comments. The technique uses a combination of natural language processing and run-time instrumentation. Our implementation, Toradocu, can be combined with a test input generation tool. Our experimental evaluation shows that Toradocu improves the fault-finding effectiveness of EvoSuite and Randoop test suites by 8\% and 16\% respectively, and reduces EvoSuite’s false positives by 33\%. },
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/2931037.2931061.pdf:PDF},
  keywords  = {Testing, oracle generation, automatic test oracle, oracle problem},
  numpages  = {12},
}

@InProceedings{IntelligentSoftwareDevelopmentEnvironments:IntegratingNaturalLanguageProcessingwiththeEclipsePlatform,
  author = {Witte, René and Sateli, Bahar and Khamis, Ninus and Rilling, Juergen},
  title  = {Intelligent Software Development Environments: Integrating Natural Language Processing with the Eclipse Platform},
  year   = {2011},
  month  = {05},
  isbn   = {978-3-642-21042-6},
  pages  = {408-419},
  doi    = {10.1007/978-3-642-21043-3_49},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/2011_Book_AdvancesInArtificialIntelligen.pdf:PDF},
}

@Article{Haque2021ActionWP,
  author  = {Sakib Haque and Aakash Bansal and Lingfei Wu and Collin McMillan},
  title   = {Action Word Prediction for Neural Source Code Summarization},
  journal = {2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  year    = {2021},
  pages   = {330--341},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Action_Word_Prediction_for_Neural_Source_Code_Summarization.pdf:PDF},
}

@Article{Csri2015ExaminingSC,
  author  = {Tam{\'a}s Cs{\'e}ri},
  title   = {Examining structural correctness of documentation comments in C++ programs},
  journal = {2015 IEEE 13th International Scientific Conference on Informatics},
  year    = {2015},
  pages   = {79-84},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Examining_structural_correctness_of_documentation_comments_in_C_programs.pdf:PDF},
}

@InProceedings{QualityoftheSourceCodeforDesignandArchitectureRecoveryTechniques:UtilitiesaretheProblem,
  author  = {Pirzadeh, Heidar and Alawneh, Luay and Hamou-Lhadj, Abdelwahab},
  title   = {Quality of the Source Code for Design and Architecture Recovery Techniques: Utilities are the Problem},
  year    = {2009},
  month   = {08},
  pages   = {465-469},
  doi     = {10.1109/QSIC.2009.69},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Quality_of_the_Source_Code_for_Design_and_Architecture_Recovery_Techniques_Utilities_are_the_Problem.pdf:PDF},
  journal = {Proceedings - International Conference on Quality Software},
}

@Article{HYATT1997223,
  author   = {Lawrence E. Hyatt and Linda H. Rosenberg},
  title    = {Software metrics program for risk assessment},
  journal  = {Acta Astronautica},
  year     = {1997},
  volume   = {40},
  number   = {2},
  pages    = {223-233},
  note     = {Enlarging The Scope of Space Applications},
  issn     = {0094-5765},
  doi      = {https://doi.org/10.1016/S0094-5765(97)00148-3},
  url      = {https://www.sciencedirect.com/science/article/pii/S0094576597001483},
  abstract = {The Software Assurance Technology Center (SATC) has developed a software metrics program consisting of goals, attributes and metrics to support the assessment of project status, risk, and product quality throughout the life cycle. The objective of the software metrics program is to assess risk areas at each phase of the development life cycle and project them into the future. The software development goals in the metrics program are evaluated by a set of attributes that help to define and classify risks. The attributes must be “measurable” by a set of metrics. These metrics must be based on data that is collectable within the confines of the software development process and must also be relevant to the quality attributes and risk assessment. This paper discusses the SATC's software risk assessment metrics program which meets these needs and is currently being applied to software developed for NASA. At each phase of the software development life cycle, attributes will be identified and metrics defined. Project data is used to demonstrate how the metric analysis was applied at that phase for risk assessment, and how that information could be used by management to manage project risks.},
  file     = {:/home/compf/data/uni/sem7/bachelor/sources/1-s2.0-S0094576597001483-main.pdf:PDF},
}

@Article{HowSoftwareEngineersUseDocumentation:TheStateofthePractice,
  author  = {Lethbridge, Timothy and Singer, Janice and Forward, Andrew},
  title   = {How Software Engineers Use Documentation: The State of the Practice},
  journal = {Software, IEEE},
  year    = {2003},
  volume  = {20},
  month   = {12},
  pages   = {35 - 39},
  doi     = {10.1109/MS.2003.1241364},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Lethbridge-Singer-Forward-2003.pdf:PDF},
}

@InProceedings{Reusabilityandmaintainabilitymetricsforobject-orientedsoftware,
  author = {Lee, Young and Chang, Kai},
  title  = {Reusability and maintainability metrics for object-oriented software},
  year   = {2000},
  month  = {01},
  pages  = {88-94},
  doi    = {10.1145/1127716.1127737},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/1127716.1127737.pdf:PDF},
}

@Article{Studytheimpactofimprovingsourcecodeonsoftwaremetrics,
  author = {Zoubi, Qosai and Alsmadi, Izzat and Abul-Huda, B.},
  title  = {Study the impact of improving source code on software metrics},
  year   = {2012},
  month  = {05},
  doi    = {10.1109/CITS.2012.6220379},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/1127716.1127737.pdf:PDF},
}

@Article{PredictingJavaSourceCodePropertiesfromaNaturalLanguageSpecification,
  author = {Turner, Kathy and Cardin, Pascal and Reid, Sam and Clawson, Joel},
  title  = {Predicting Java Source Code Properties from a Natural Language Specification},
  year   = {2021},
  month  = {11},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/10.1.1.91.3692.pdf:PDF},
}

@Misc{HowtoWriteDocCommentsfortheJavadocTool,
  title   = {How to Write Doc Comments for the Javadoc Tool},
  url     = {https://www.oracle.com/de/technical-resources/articles/java/javadoc-tool.html#styleguide},
  journal = {How to Write Doc Comments for the Javadoc Tool | Oracle Deutschland},
}

@Book{martin2009clean,
  author    = {Martin, Robert C},
  title     = {Clean code: a handbook of agile software craftsmanship},
  year      = {2009},
  publisher = {Pearson Education},
}

@InProceedings{10.1145/1858996.1859006,
  author    = {Sridhara, Giriprasad and Hill, Emily and Muppaneni, Divya and Pollock, Lori and Vijay-Shanker, K.},
  title     = {Towards Automatically Generating Summary Comments for Java Methods},
  booktitle = {Proceedings of the IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2010},
  series    = {ASE '10},
  publisher = {Association for Computing Machinery},
  location  = {Antwerp, Belgium},
  isbn      = {9781450301169},
  pages     = {43–52},
  doi       = {10.1145/1858996.1859006},
  url       = {https://doi.org/10.1145/1858996.1859006},
  abstract  = {Studies have shown that good comments can help programmers quickly understand what a method does, aiding program comprehension and software maintenance. Unfortunately, few software projects adequately comment the code. One way to overcome the lack of human-written summary comments, and guard against obsolete comments, is to automatically generate them. In this paper, we present a novel technique to automatically generate descriptive summary comments for Java methods. Given the signature and body of a method, our automatic comment generator identifies the content for the summary and generates natural language text that summarizes the method's overall actions. According to programmers who judged our generated comments, the summaries are accurate, do not miss important content, and are reasonably concise.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/1858996.1859006.pdf:PDF},
  keywords  = {natural language program analysis, comment generation, method summarization},
  numpages  = {10},
}

@InProceedings{10.1145/1159733.1159738,
  author    = {Arisholm, Erik and Briand, Lionel C.},
  title     = {Predicting Fault-Prone Components in a Java Legacy System},
  booktitle = {Proceedings of the 2006 ACM/IEEE International Symposium on Empirical Software Engineering},
  year      = {2006},
  series    = {ISESE '06},
  publisher = {Association for Computing Machinery},
  location  = {Rio de Janeiro, Brazil},
  isbn      = {1595932186},
  pages     = {8–17},
  doi       = {10.1145/1159733.1159738},
  url       = {https://doi.org/10.1145/1159733.1159738},
  abstract  = {This paper reports on the construction and validation of faultproneness prediction models in the context of an object-oriented, evolving, legacy system. The goal is to help QA engineers focus their limited verification resources on parts of the system likely to contain faults. A number of measures including code quality, class structure, changes in class structure, and the history of class-level changes and faults are included as candidate predictors of class fault-proneness. A cross-validated classification analysis shows that the obtained model has less than 20\% of false positives and false negatives, respectively. However, as shown in this paper, statistics regarding the classification accuracy tend to inflate the potential usefulness of the fault-proneness prediction models. We thus propose a simple and pragmatic methodology for assessing the costeffectiveness of the predictions to focus verification effort. On the basis of the cost-effectiveness analysis we show that change and fault data from previous releases is paramount to developing a practically useful prediction model. When our model is applied to predict faults in a new release, the estimated potential savings in verification effort is about 29\%. In contrast, the estimated savings in verification effort drops to 0\% when history data is not included.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/1159733.1159738.pdf:PDF},
  numpages  = {10},
}

@InProceedings{7332619,
  author    = {Maldonado, Everton da S. and Shihab, Emad},
  title     = {Detecting and quantifying different types of self-admitted technical Debt},
  booktitle = {2015 IEEE 7th International Workshop on Managing Technical Debt (MTD)},
  year      = {2015},
  pages     = {9-15},
  doi       = {10.1109/MTD.2015.7332619},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Detecting_and_quantifying_different_types_of_self-admitted_technical_Debt.pdf:PDF},
}

@InProceedings{AnalyzingProgramComprehensibilityofGoProjects,
  author = {Asad, Moumita and Yasir, Rafed and Shahriar, Shihab and Nahar, Nadia and Tawhid, Md. Nurul Ahad},
  title  = {Analyzing Program Comprehensibility of Go Projects},
  year   = {2021},
  month  = {07},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/paper152.pdf:PDF},
}

@Article{5332232,
  author  = {Buse, Raymond P.L. and Weimer, Westley R.},
  title   = {Learning a Metric for Code Readability},
  journal = {IEEE Transactions on Software Engineering},
  year    = {2010},
  volume  = {36},
  number  = {4},
  pages   = {546-558},
  doi     = {10.1109/TSE.2009.70},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Learning_a_Metric_for_Code_Readability.pdf:PDF},
}

@Article{CHEN201945,
  author   = {Huanchao Chen and Yuan Huang and Zhiyong Liu and Xiangping Chen and Fan Zhou and Xiaonan Luo},
  title    = {Automatically detecting the scopes of source code comments},
  journal  = {Journal of Systems and Software},
  year     = {2019},
  volume   = {153},
  pages    = {45-63},
  issn     = {0164-1212},
  doi      = {https://doi.org/10.1016/j.jss.2019.03.010},
  url      = {https://www.sciencedirect.com/science/article/pii/S016412121930055X},
  abstract = {Comments convey useful information about the system functionalities and many methods for software engineering tasks take comments as an important source for many software engineering tasks such as code semantic analysis, code reuse and so on. However, unlike structural doc comments, it is challenging to identify the relationship between the functional semantics of the code and its corresponding textual descriptions nested inside the code and apply it to automatic analyzing and mining approaches in software engineering tasks efficiently. In this paper, we propose a general method for the detection of source code comment scopes. Based on machine learning, our method utilized features of code snippets and comments to detect the scopes of source code comments automatically in Java programs. On the dataset of comment-statement pairs from 4 popular open source projects, our method achieved a high accuracy of 81.45\% in detecting the scopes of comments. Furthermore, the results demonstrated the feasibility and effectiveness of our comment scope detection method on new projects. Moreover, our method was applied to two specific software engineering tasks in our studies: analyzing software repositories for outdated comment detection and mining software repositories for comment generation. As a general approach, our method provided a solution to comment-code mapping. It improved the performance of baseline methods in both tasks, which demonstrated that our method is conducive to automatic analyzing and mining approaches on software repositories.},
  file     = {:/home/compf/data/uni/sem7/bachelor/sources/1-s2.0-S016412121930055X-main.pdf:PDF},
  keywords = {Comment scope detection, Machine learning, Software repositories},
}

@InProceedings{10.1145/1555860.1555866,
  author    = {Cifuentes, Cristina and Hoermann, Christian and Keynes, Nathan and Li, Lian and Long, Simon and Mealy, Erica and Mounteney, Michael and Scholz, Bernhard},
  title     = {BegBunch: Benchmarking for C Bug Detection Tools},
  booktitle = {Proceedings of the 2nd International Workshop on Defects in Large Software Systems: Held in Conjunction with the ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA 2009)},
  year      = {2009},
  series    = {DEFECTS '09},
  publisher = {Association for Computing Machinery},
  location  = {Chicago, Illinois},
  isbn      = {9781605586540},
  pages     = {16–20},
  doi       = {10.1145/1555860.1555866},
  url       = {https://doi.org/10.1145/1555860.1555866},
  abstract  = {Benchmarks for bug detection tools are still in their infancy. Though in recent years various tools and techniques were introduced, little effort has been spent on creating a benchmark suite and a harness for a consistent quantitative and qualitative performance measurement. For assessing the performance of a bug detection tool and determining which tool is better than another for the type of code to be looked at, the following questions arise: 1) how many bugs are correctly found, 2) what is the tool's average false positive rate, 3) how many bugs are missed by the tool altogether, and 4) does the tool scale.In this paper we present our contribution to the C bug detection community: two benchmark suites that allow developers and users to evaluate accuracy and scalability of a given tool. The two suites contain buggy, mature open source code; bugs are representative of "real world" bugs. A harness accompanies each benchmark suite to compute automatically qualitative and quantitative performance of a bug detection tool.BegBunch has been tested to run on the Solaris™, Mac OS X and Linux operating systems. We show the generality of the harness by evaluating it with our own Parfait and three publicly available bug detection tools developed by others.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/1555860.1555866.pdf:PDF},
  keywords  = {accuracy, scalability},
  numpages  = {5},
}

@InProceedings{883030,
  author    = {Godfrey and Qiang Tu},
  title     = {Evolution in open source software: a case study},
  booktitle = {Proceedings 2000 International Conference on Software Maintenance},
  year      = {2000},
  pages     = {131-142},
  doi       = {10.1109/ICSM.2000.883030},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Evolution_in_open_source_software_a_case_study.pdf:PDF},
}

@Article{Aggarwal2002AnIM,
  author  = {K. K. Aggarwal and Yogesh Singh and Jitender Kumar Chhabra},
  title   = {An integrated measure of software maintainability},
  journal = {Annual Reliability and Maintainability Symposium. 2002 Proceedings (Cat. No.02CH37318)},
  year    = {2002},
  pages   = {235-241},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/An_integrated_measure_of_software_maintainability.pdf:PDF},
}

@WWW{Minimatch,
  date = {2021-11-30},
  url  = {https://github.com/isaacs/minimatch},
}

@WWW{antlr_grammar_github,
  date = {2021-11-30},
  url  = {https://github.com/antlr/grammars-v4/tree/master/java/java},
}

@InProceedings{Doautomaticrefactoringsimprovemaintainability?Anindustrialcasestudy,
  author    = {Szőke, Gábor and Nagy, Csaba and Hegedűs, Péter and Ferenc, Rudolf and Gyimóthy, Tibor},
  title     = {Do automatic refactorings improve maintainability? An industrial case study},
  booktitle = {2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  year      = {2015},
  pages     = {429-438},
  doi       = {10.1109/ICSM.2015.7332494},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Do_automatic_refactorings_improve_maintainability_An_industrial_case_study.pdf:PDF},
}

@InProceedings{OntheUseofPropertiesinJavaApplications,
  author    = {Lumpe, Markus and Mahmud, Samiran and Vasa, Rajesh},
  title     = {On the Use of Properties in Java Applications},
  booktitle = {2010 21st Australian Software Engineering Conference},
  year      = {2010},
  pages     = {235-244},
  doi       = {10.1109/ASWEC.2010.35},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/On_the_Use_of_Properties_in_Java_Applications.pdf:PDF},
}

@WWW{javabeans,
  author  = {Sun Microsystems},
  url     = {https://download.oracle.com/otndocs/jcp/7224-javabeans-1.01-fr-spec-oth-JSpec/},
  urldate = {2021-12-01},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/beans.101.pdf:PDF},
}

@WWW{Java-parser,
  title   = {Java-parser},
  url     = {https://www.npmjs.com/package/java-parser},
  urldate = {2021-12-01},
}

@Misc{gholba2012measures,
  author = {Gholba, MJ},
  title  = {Measures of Central Tendency},
  year   = {2012},
  file   = {:Measures of Central Tendency.pdf:PDF},
}

@Article{YAGER199835,
  author   = {Ronald R. Yager},
  title    = {Fusion of ordinal information using weighted median aggregation},
  journal  = {International Journal of Approximate Reasoning},
  year     = {1998},
  volume   = {18},
  number   = {1},
  pages    = {35-52},
  issn     = {0888-613X},
  doi      = {https://doi.org/10.1016/S0888-613X(97)10003-2},
  url      = {https://www.sciencedirect.com/science/article/pii/S0888613X97100032},
  abstract = {The weighted median is introduced as a fusion operation which can be used in situations in which, while having numeric values for the weights associated with the objects to be fused, the actual objects being fused only satisfy an ordering property. After introducing the concept of weighted median we compare it with the weighted average and show that they have many properties in common. We then provide an algorithm for learning the weights associated with a median aggregation. We then show how we can use this technique to extend the applicability of the Ordered Weighted Averaging (OWA) operator to situations in which the arguments are nonnumeric. Finally we show how we can use the weighted median as an alternative to the expected value in the evaluation of probabilistic lotteries.},
  file     = {:/home/compf/1-s2.0-S0888613X97100032-main.pdf:PDF},
}

@Book{TheDefinitiveANTLR4Reference,
  author    = {Parr, Terence},
  title     = {The Definitive ANTLR 4 Reference},
  year      = {2013},
  edition   = {2nd},
  publisher = {Pragmatic Bookshelf},
  isbn      = {1934356999},
  abstract  = {Programmers run into parsing problems all the time. Whether it's a data format like JSON, a network protocol like SMTP, a server configuration file for Apache, a PostScript/PDF file, or a simple spreadsheet macro language--ANTLR v4 and this book will demystify the process. ANTLR v4 has been rewritten from scratch to make it easier than ever to build parsers and the language applications built on top. This completely rewritten new edition of the bestselling Definitive ANTLR Reference shows you how to take advantage of these new features. Build your own languages with ANTLR v4, using ANTLR's new advanced parsing technology. In this book, you'll learn how ANTLR automatically builds a data structure representing the input (parse tree) and generates code that can walk the tree (visitor). You can use that combination to implement data readers, language interpreters, and translators. You'll start by learning how to identify grammar patterns in language reference manuals and then slowly start building increasingly complex grammars. Next, you'll build applications based upon those grammars by walking the automatically generated parse trees. Then you'll tackle some nasty language problems by parsing files containing more than one language (such as XML, Java, and Javadoc). You'll also see how to take absolute control over parsing by embedding Java actions into the grammar. You'll learn directly from well-known parsing expert Terence Parr, the ANTLR creator and project lead. You'll master ANTLR grammar construction and learn how to build language tools using the built-in parse tree visitor mechanism. The book teaches using real-world examples and shows you how to use ANTLR to build such things as a data file reader, a JSON to XML translator, an R parser, and a Java class-interface extractor. This book is your ticket to becoming a parsing guru!What You Need: ANTLR 4.0 and above. Java development tools. Ant build system optional (needed for building ANTLR from source)},
}

@InProceedings{icomment,
  author    = {Tan, Lin and Yuan, Ding and Krishna, Gopal and Zhou, Yuanyuan},
  title     = {/*icomment: Bugs or Bad Comments?*/},
  booktitle = {Proceedings of Twenty-First ACM SIGOPS Symposium on Operating Systems Principles},
  year      = {2007},
  series    = {SOSP '07},
  publisher = {Association for Computing Machinery},
  location  = {Stevenson, Washington, USA},
  isbn      = {9781595935915},
  pages     = {145–158},
  doi       = {10.1145/1294261.1294276},
  url       = {https://doi.org/10.1145/1294261.1294276},
  abstract  = {Commenting source code has long been a common practice in software development. Compared to source code, comments are more direct, descriptive and easy-to-understand. Comments and sourcecode provide relatively redundant and independent information regarding a program's semantic behavior. As software evolves, they can easily grow out-of-sync, indicating two problems: (1) bugs -the source code does not follow the assumptions and requirements specified by correct program comments; (2) bad comments - comments that are inconsistent with correct code, which can confuse and mislead programmers to introduce bugs in subsequent versions. Unfortunately, as most comments are written in natural language, no solution has been proposed to automatically analyze commentsand detect inconsistencies between comments and source code. This paper takes the first step in automatically analyzing commentswritten in natural language to extract implicit program rulesand use these rules to automatically detect inconsistencies between comments and source code, indicating either bugs or bad comments. Our solution, iComment, combines Natural Language Processing(NLP), Machine Learning, Statistics and Program Analysis techniques to achieve these goals. We evaluate iComment on four large code bases: Linux, Mozilla, Wine and Apache. Our experimental results show that iComment automatically extracts 1832 rules from comments with 90.8-100\% accuracy and detects 60 comment-code inconsistencies, 33 newbugs and 27 bad comments, in the latest versions of the four programs. Nineteen of them (12 bugs and 7 bad comments) have already been confirmed by the corresponding developers while the others are currently being analyzed by the developers.},
  address   = {New York, NY, USA},
  keywords  = {programming rules and static analysis, natural language processing for software engineering, comment analysis},
  numpages  = {14},
}

@InProceedings{InferringResourceSpecificationsfromNaturalLanguageAPIDocumentation,
  author  = {Zhong, Hao and Zhang, Lu and Xie, Tao and Mei, Hong},
  title   = {Inferring Resource Specifications from Natural Language API Documentation},
  year    = {2009},
  month   = {11},
  pages   = {307-318},
  doi     = {10.1109/ASE.2009.94},
  file    = {:/home/compf/Inferring_Resource_Specifications_from_Natural_Lan.pdf:PDF},
  journal = {ASE2009 - 24th IEEE/ACM International Conference on Automated Software Engineering},
}

@Comment{jabref-meta: databaseType:biblatex;}
